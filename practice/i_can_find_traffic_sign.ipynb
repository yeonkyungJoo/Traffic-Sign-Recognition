{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 필터 커널 세팅\n",
    "kernel = np.ones((1, 1), np.uint8)\n",
    "kernel2 = np.ones((3, 3), np.uint8)\n",
    "\n",
    "############################################################################################################\n",
    "    # 마지막 코드 #\n",
    "############################################################################################################\n",
    "\n",
    "# 영상 경로 설정\n",
    "video_path= './test_data/video10.mp4'\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "# 영상 이름\n",
    "video_file = video_path.split('/')[-1]\n",
    "video_name = video_file.split('.')[0]\n",
    "\n",
    "# 필터 \n",
    "red1 = np.array([0, 30, 10]) # 밝은 빨강(주황계열)\n",
    "red2 = np.array([7, 250, 230])\n",
    "\n",
    "red3 = np.array([155, 30, 10]) # 어두운 빨강(갈색계열)\n",
    "red4 = np.array([180, 250, 230])\n",
    "\n",
    "# 필터 커널 세팅\n",
    "kernel = np.ones((2, 2), np.uint8)\n",
    "kernel2 = np.ones((4, 4), np.uint8)\n",
    "\n",
    "#frame_move = int(cap.get(cv2.CAP_PROP_FRAME_COUNT)   )\n",
    "#cap.set(cv2.CAP_PROP_POS_FRAMES, frame_move)\n",
    "###################################################################################################################\n",
    "while cap.isOpened() :\n",
    "    #######################################################\n",
    "    # 영상 읽기\n",
    "    ret, img = cap.read()\n",
    "    \n",
    "    # 마지막 프레임 확인\n",
    "    if ret is None:\n",
    "        break\n",
    "    img = cv2.resize(img, (img.shape[1]//2, img.shape[0]//2),  interpolation=cv2.INTER_AREA)\n",
    "    \n",
    "    yuv = cv2.cvtColor(img, cv2.COLOR_BGR2YUV)\n",
    "    #yuv[yuv[:, :, 2]<170] = 0\n",
    "    yuv[yuv[:, :, 2]<140] = 0\n",
    "    yuv[yuv[:, :, 1]<110] = 0\n",
    "    yuv[yuv[:, :, 0]>200] = 0\n",
    "    img2 = yuv[ : , : , 2]\n",
    "    cv2.imshow('img2', img2)\n",
    "    # print(yuv[:, :, 2])\n",
    "    \n",
    "\n",
    "    thr, yuv_red = cv2.threshold(img2, 140, 255, cv2.THRESH_BINARY)\n",
    "    \n",
    "    cv2.imshow('yuv_red', yuv_red)\n",
    "    erosion_mask = cv2.erode(yuv_red, kernel, iterations=1)\n",
    "    dilation_mask = cv2.dilate(erosion_mask, kernel2, iterations=1) \n",
    "\n",
    "\n",
    "    edges = cv2.Canny(img, 100,200)\n",
    "    \n",
    "    dilation_mask2 = cv2.dilate(edges, kernel2, iterations=1) \n",
    "    erosion_mask2 = cv2.erode(dilation_mask2, kernel, iterations=1)\n",
    "\n",
    "    res_red2 = cv2.bitwise_and(dilation_mask, dilation_mask, mask =dilation_mask2)\n",
    "    \n",
    "    cv2.imshow('res_red2', res_red2)\n",
    "    \n",
    "    _, contours, hierarchy = cv2.findContours(res_red2, cv2.RETR_CCOMP, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    mask_external = np.zeros(res_red2.shape, res_red2.dtype)\n",
    "    \n",
    "    for i in range(len(contours)) :\n",
    "        if hierarchy[0][i][3] == -1 :\n",
    "            cv2.drawContours(mask_external, contours, i, 255, -1)\n",
    "\n",
    "    mask_internal = np.zeros(res_red2.shape, res_red2.dtype)\n",
    "    \n",
    "    for i in range(len(contours)) :\n",
    "        if hierarchy[0][i][3] != -1 :\n",
    "            cv2.drawContours(mask_internal, contours, i, 255, -1)\n",
    "                    \n",
    "    _, _, stats_i, centroids_i = cv2.connectedComponentsWithStats(mask_internal)\n",
    "    _, _, stats_e, centroids_e = cv2.connectedComponentsWithStats(mask_external)\n",
    "    \n",
    "    for idx, centroid_i in enumerate(centroids_i) :\n",
    "        \n",
    "        if stats_i[idx][0] == 0 and stats_i[idx][1] == 0 :\n",
    "            continue\n",
    "        if np.any(np.isnan(centroid_i)) :\n",
    "            continue\n",
    "            \n",
    "        for centroid_e in centroids_e :\n",
    "            if abs(centroid_i[0] - centroid_e[0]) < 5 and abs(centroid_i[1] - centroid_e[1]) < 5 :\n",
    "                x, y, w, h, area = stats_i[idx]\n",
    "                centerX, centerY = int(centroid_i[0]), int(centroid_i[1])\n",
    "\n",
    "                if area > 120 and abs(w-h) < 5 :\n",
    "                    try : \n",
    "                        detected_img = img[y-10 : y+h+10,  x-10 : x+w+10]\n",
    "                        gray_detected_img = cv2.cvtColor(detected_img, cv2.COLOR_BGR2GRAY)\n",
    "                        circles = cv2.HoughCircles(gray_detected_img, cv2.HOUGH_GRADIENT, 1, 100, param1=100, param2=45,minRadius=7, maxRadius=40)\n",
    "                        if circles is not None :\n",
    "                            circles = np.uint16(np.around(circles))\n",
    "\n",
    "                            for i in circles[0, :] :\n",
    "                                cv2.circle(img, ( centerX, centerY ), 2, (0, 255, 0), 2)\n",
    "                                cv2.rectangle(img, (x-10, y-10), (x+w+10, y+h+10), (0, 0, 255), 2)\n",
    "                    except : \n",
    "                        continue\n",
    "\n",
    "\n",
    "    cv2.imshow(video_file, img)\n",
    "\n",
    "    \n",
    "    if cv2.waitKey(1) == 27 :\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 필터 커널 세팅\n",
    "kernel = np.ones((1, 1), np.uint8)\n",
    "kernel2 = np.ones((3, 3), np.uint8)\n",
    "\n",
    "############################################################################################################\n",
    "    # 마지막 코드 #\n",
    "############################################################################################################\n",
    "\n",
    "# 영상 경로 설정\n",
    "video_path= './test_data/new.mp4'\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "# 영상 이름\n",
    "video_file = video_path.split('/')[-1]\n",
    "video_name = video_file.split('.')[0]\n",
    "\n",
    "# 필터 \n",
    "red1 = np.array([0, 30, 10]) # 밝은 빨강(주황계열)\n",
    "red2 = np.array([7, 250, 230])\n",
    "\n",
    "red3 = np.array([155, 30, 10]) # 어두운 빨강(갈색계열)\n",
    "red4 = np.array([180, 250, 230])\n",
    "\n",
    "# 필터 커널 세팅\n",
    "kernel = np.ones((2, 2), np.uint8)\n",
    "kernel2 = np.ones((4, 4), np.uint8)\n",
    "\n",
    "#frame_move = int(cap.get(cv2.CAP_PROP_FRAME_COUNT)   )\n",
    "#cap.set(cv2.CAP_PROP_POS_FRAMES, frame_move)\n",
    "###################################################################################################################\n",
    "while cap.isOpened() :\n",
    "    #######################################################\n",
    "    # 영상 읽기\n",
    "    ret, img = cap.read()\n",
    "    \n",
    "    # 마지막 프레임 확인\n",
    "    if ret is None:\n",
    "        break\n",
    "        \n",
    "    # 이미지 크기 변경\n",
    "    img = cv2.resize(img, (img.shape[1] //2, img.shape[0]//2),  interpolation=cv2.INTER_AREA)\n",
    "    \n",
    "    # ROI 영역 추출\n",
    "    new_img = np.zeros(img.shape, img.dtype)\n",
    "    new_img[0 : img.shape[0]*2//3, : ] = img[0 : img.shape[0]*2//3 ,  : ]\n",
    "    #cv2.imshow('new_img', new_img)\n",
    "    \n",
    "    # 1. 색 공간 변환 ( BGR -> YUV)\n",
    "    yuv = cv2.cvtColor(new_img, cv2.COLOR_BGR2YUV)\n",
    "    #yuv[yuv[:, :, 2]<170] = 0\n",
    "    yuv[yuv[:, :, 2]<135] = 0\n",
    "    yuv[yuv[:, :, 1]<110] = 0\n",
    "    yuv[yuv[:, :, 0]>230] = 0\n",
    "    img2 = yuv[ : , : , 2]\n",
    "    \n",
    "    # 스레드숄드 / 침식 / 팽창 적용 \n",
    "    thr, yuv_red = cv2.threshold(img2, 140, 255, cv2.THRESH_BINARY)\n",
    "    erosion_mask = cv2.erode(yuv_red, kernel, iterations=1)\n",
    "    dilation_mask = cv2.dilate(erosion_mask, kernel2, iterations=1) \n",
    "    #cv2.imshow('dilation_mask', dilation_mask)\n",
    "###########################################################################\n",
    "    # 2. 캐니 엣지 \n",
    "    edges = cv2.Canny(new_img, 100,200)\n",
    "    \n",
    "    # 침식 /팽창 적용\n",
    "    dilation_mask2 = cv2.dilate(edges, kernel, iterations=1) \n",
    "    erosion_mask2 = cv2.erode(dilation_mask2, kernel, iterations=1)\n",
    "    #cv2.imshow('erosion_mask2', erosion_mask2)\n",
    "    \n",
    "    #이미지 bitwise_and 연산\n",
    "    res_red2 = cv2.bitwise_and(dilation_mask, dilation_mask, mask =erosion_mask2)\n",
    "    #cv2.imshow('res_red2', res_red2)\n",
    "    \n",
    "###########################################################################\n",
    "    ## 3. 컨투어 / 허프 원 추출 ##\n",
    "    _, contours, hierarchy = cv2.findContours(res_red2, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    mask_internal = np.zeros(res_red2.shape, res_red2.dtype)\n",
    "    \n",
    "    cv2.drawContours(mask_internal, contours, -1, 255, 2)\n",
    "\n",
    "    cv2.imshow('mask_internal', mask_internal)\n",
    "    \n",
    "    _, _, stats_i, centroids_i = cv2.connectedComponentsWithStats(mask_internal)\n",
    "    \n",
    "    \n",
    "    for idx, centroid_i in enumerate(centroids_i) :\n",
    "        \n",
    "        if stats_i[idx][0] == 0 and stats_i[idx][1] == 0 :\n",
    "            continue\n",
    "        if np.any(np.isnan(centroid_i)) :\n",
    "            continue       \n",
    "    \n",
    "        x, y, w, h, area = stats_i[idx]\n",
    "        centerX, centerY = int(centroid_i[0]), int(centroid_i[1])\n",
    "        \n",
    "        if area < 1700 and area > 200 and abs(w-h) < 5 :\n",
    "            try : \n",
    "                detected_img = img[y+7 : y+h+7,  x+7 : x+w+7]\n",
    "                gray_detected_img = cv2.cvtColor(detected_img, cv2.COLOR_BGR2GRAY)\n",
    "                circles = cv2.HoughCircles(gray_detected_img, cv2.HOUGH_GRADIENT, 1, 100, param1=100, param2=45,minRadius=5, maxRadius=38)\n",
    "                if circles is not None :\n",
    "                    circles = np.uint16(np.around(circles))\n",
    "                    for i in circles[0, :] :\n",
    "                        print(area)\n",
    "                        cv2.circle(img, ( centerX, centerY ), 2, (0, 255, 0), 2)\n",
    "                        cv2.rectangle(img, (x+7, y+7), (x+w+7, y+h+7), (0, 0, 255), 2)\n",
    "            except : \n",
    "                continue\n",
    "\n",
    "    \n",
    "    cv2.imshow(video_file, img)\n",
    "\n",
    "    \n",
    "    if cv2.waitKey(1) == 27 :\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow-gpu",
   "language": "python",
   "name": "py374"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
