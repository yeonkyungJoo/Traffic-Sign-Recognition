{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 커널\n",
    "kernel1 = np.ones((2, 2), np.uint8)\n",
    "kernel2 = np.ones((4, 4), np.uint8)\n",
    "\n",
    "# 데이터 경로\n",
    "video_path = './video_data/n_video6.mp4'\n",
    "video_file = video_path.split('/')[-1]\n",
    "video_name = video_file.split('.')[0]\n",
    "\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "# 프레임 이동\n",
    "# frame_move = int(cap.get(cv2.CAP_PROP_FRAME_COUNT) // 2)\n",
    "# cap.set(cv2.CAP_PROP_POS_FRAMES, frame_move)\n",
    "\n",
    "while cap.isOpened() :\n",
    "    ret, img = cap.read()\n",
    "    \n",
    "    # 다음 프레임 확인 \n",
    "    if ret is False : # if img is None :\n",
    "        break\n",
    "    \n",
    "    # 이미지 크기 변경\n",
    "    img = cv2.resize(img, (img.shape[1] //2, img.shape[0]//2),  interpolation=cv2.INTER_AREA)\n",
    "    \n",
    "    ######### 1. ROI 영역 추출 #########\n",
    "    \n",
    "    # 1) 표지판 ROI\n",
    "    img_ts = np.zeros(img.shape, img.dtype)\n",
    "    img_ts[0: img.shape[0]*2//3, :] = img[0: img.shape[0]*2//3, :]\n",
    "    #cv2.imshow('img_ts', img_ts)\n",
    "    \n",
    "    # 2) 도로 ROI\n",
    "    img_road = np.zeros(img.shape, img.dtype)\n",
    "    img_road[0: img.shape[0]*2//3, :] = img_road[0: img.shape[0]*2//3, :]\n",
    "    # cv2.imshow('img_road', img_road)\n",
    "    \n",
    "    ######### 2. 붉은색 검출용 마스크 생성 #########\n",
    "    \n",
    "    # 색 공간 변환(BGR -> YUV)\n",
    "    img_ts_yuv = cv2.cvtColor(img_ts, cv2.COLOR_BGR2YUV)\n",
    "    img_ts_yuv[img_ts_yuv[:, :, 2]<135] = 0\n",
    "    img_ts_yuv[img_ts_yuv[:, :, 1]<110] = 0\n",
    "    img_ts_yuv[img_ts_yuv[:, :, 0]>230] = 0\n",
    "    img_ts_yuv_red = img_ts_yuv[ : , : , 2]\n",
    "    \n",
    "    # 이진화\n",
    "    th, ts_red = cv2.threshold(img_ts_yuv_red, 140, 255, cv2.THRESH_BINARY)\n",
    "    # 침식\n",
    "    ts_red_erosion_mask = cv2.erode(ts_red, kernel1, iterations=1)\n",
    "    # 팽창\n",
    "    ts_red_dilation_mask = cv2.dilate(ts_red_erosion_mask, kernel2, iterations=1)\n",
    "    cv2.imshow('ts_red_dilation_mask', ts_red_dilation_mask)\n",
    "    \n",
    "    ######### 3. 조명 영향 제거용 마스크 생성 #########\n",
    "    \n",
    "    # 캐니 엣지\n",
    "    ts_edge = cv2.Canny(img_ts, 100, 200)\n",
    "    \n",
    "    # 팽창\n",
    "    ts_edge_dilation_mask = cv2.dilate(ts_edge, kernel1, iterations = 1)\n",
    "    # 침식\n",
    "    ts_edge_erosion_mask = cv2.erode(ts_edge_dilation_mask, kernel1, iterations = 1)\n",
    "    cv2.imshow('ts_edge_erosion_mask', ts_edge_erosion_mask)\n",
    "    \n",
    "    ######### 4. 마스크 합성 #########\n",
    "    ts_mask = cv2.bitwise_and(ts_red_dilation_mask, ts_red_dilation_mask, mask = ts_edge_erosion_mask)\n",
    "    #cv2.imshow('ts_mask', ts_mask)\n",
    "    \n",
    "    ######### 5. 원 검출 #########\n",
    "    \n",
    "    # 컨투어 찾기(RETR_EXTERNAL / RETR_TREE )\n",
    "    _, contours, hierarchy = cv2.findContours(ts_mask, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    # 찾은 컨투어 그리기\n",
    "    ts_contours = np.zeros(ts_mask.shape, ts_mask.dtype)\n",
    "    cv2.drawContours(ts_contours, contours, -1, 255, 2)\n",
    "    \n",
    "    # 객체 찾기\n",
    "    _, _, stats, centroids = cv2.connectedComponentsWithStats(ts_contours)\n",
    "    \n",
    "    for idx, centroid in enumerate(centroids) :\n",
    "        if stats[idx][0] == 0 and stats[idx][1] == 0 :\n",
    "            continue\n",
    "        if np.any(np.isnan(centroid)) :\n",
    "            continue\n",
    "            \n",
    "        x, y, w, h, area = stats[idx]\n",
    "        centerX, centerY = int(centroid[0]), int(centroid[1])\n",
    "        \n",
    "        if area > 200 and area < 1700 and abs(w-h) < 5 :\n",
    "            try :\n",
    "                detected_img = img[y-7 : y+h+7,  x-7 : x+w+7]\n",
    "                gray_detected_img = cv2.cvtColor(detected_img, cv2.COLOR_BGR2GRAY)\n",
    "                circles = cv2.HoughCircles(gray_detected_img, cv2.HOUGH_GRADIENT, 1, 100, param1=100, param2=45,minRadius=5, maxRadius=38)\n",
    "                \n",
    "                if circles is not None :\n",
    "                    circles = np.uint16(np.around(circles))\n",
    "                    for i in circles[0, :] :\n",
    "                        cv2.circle(img, (centerX, centerY), 2, (0, 255, 0), 2)\n",
    "                        cv2.rectangle(img, (x-7, y-7), (x+w+7, y+h+7), (0, 0, 255), 2)\n",
    "            except :\n",
    "                continue\n",
    "                \n",
    "    cv2.imshow(video_name, img)\n",
    "    \n",
    "    if cv2.waitKey(1) == 27 :\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 표지판 검출 함수화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow-gpu",
   "language": "python",
   "name": "py374"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
