{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 표지판 예측 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# 파일 열고 URL주소 뒤에 [ ?kernel_name=py374 ] <- 붙여서 실행\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import random\n",
    "import os\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "import time\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Activation, Dropout, Flatten, Dense, GlobalAveragePooling2D, Conv2D, Conv2DTranspose, LeakyReLU, UpSampling2D\n",
    "from keras import optimizers\n",
    "# \n",
    "from keras.layers.normalization import BatchNormalization as BN\n",
    "\n",
    "from keras.layers import Lambda, Reshape, Add, AveragePooling2D, MaxPooling2D, Concatenate, SeparableConv2D\n",
    "from keras.models import Model\n",
    "from keras.losses import mse, binary_crossentropy\n",
    "from keras.utils import plot_model\n",
    "from keras import backend as K\n",
    "\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "from keras.regularizers import l2\n",
    "\n",
    "from keras.preprocessing.image import array_to_img, img_to_array, load_img\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from PIL import Image, ImageDraw, ImageFilter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.9\n",
    "sess  = tf.Session(config=config) \n",
    "keras.backend.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터세트 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dir_url : ./data/train/\n",
      "[INFO] loading images...\n",
      "NO_U-turn\n",
      "NO_left\n",
      "NO_parking_stop\n",
      "50\n",
      "60\n",
      "NO_right\n",
      "30\n",
      "[INFO] End loading images...\n"
     ]
    }
   ],
   "source": [
    "dir_url = './data/train/'\n",
    "\n",
    "print( 'dir_url : {}'.format(dir_url) )\n",
    "files = os.listdir(dir_url)\n",
    "i = 1\n",
    "\n",
    "print(\"[INFO] loading images...\")\n",
    "LABELS = set( [\"30\",\"50\",\"60\",\"NO_U-turn\",\"NO_left\",\"NO_parking_stop\",\"NO_right\"] )\n",
    "data = []\n",
    "labels = []\n",
    "train_path = './data/train'\n",
    "\n",
    "for files_list in files : \n",
    "    print(files_list) # 30, 50, 60\n",
    "    file = os.listdir(dir_url+files_list)\n",
    "    for image in os.listdir(dir_url+files_list):\n",
    "        imagepath = train_path + '/' + files_list + '/' + image\n",
    "        \n",
    "        img = cv2.imread(imagepath)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        img = cv2.resize(img,(64,64) )\n",
    "        data.append(img)\n",
    "        \n",
    "        if files_list not in LABELS:\n",
    "            continue\n",
    "        labels.append(files_list)\n",
    "        \n",
    "\n",
    "# convert the data and labels to NumPy arrays\n",
    "print(\"[INFO] End loading images...\")\n",
    "data = np.array(data)\n",
    "labels = np.array(labels)\n",
    "\n",
    "data = data / 255.0 \n",
    "\n",
    "# perform one-hot encoding on the labels\n",
    "lb = LabelBinarizer()\n",
    "labels = lb.fit_transform(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3018, 64, 64, 3)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터 셋 크기 확인\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['30', '50', '60', 'NO_U-turn', 'NO_left', 'NO_parking_stop',\n",
       "       'NO_right'], dtype='<U15')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 레이블 확인\n",
    "lb.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 레이블 길이 확인\n",
    "len(lb.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3018, 7)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 분리 - train / test 용\n",
    "(trainX, testX, trainY, testY) = train_test_split(data, labels, test_size=0.25, stratify=labels, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 생성\n",
    "\n",
    "- 컨볼루션 레이어 : 입력 이미지 크기 64 x 64, 입력 이미지 채널 3개, 필터 크기 3 x 3, 필터 수 32개, 활성화 함수 ‘relu’\n",
    "- 맥스풀링 레이어 : 풀 크기 2 x 2\n",
    "- 드롭 레이어\n",
    "- 컨볼루션 레이어 : 필터 크기 3 x 3, 필터 수 64개, 활성화 함수 ‘relu’\n",
    "- 맥스풀링 레이어 : 풀 크기 2 x 2\n",
    "- 드롭 레이어\n",
    "- 플래튼 레이어\n",
    "- 덴스 레이어 : 출력 뉴런 수 128개, 활성화 함수 ‘relu’\n",
    "- 드롭 레이어\n",
    "- 덴스 레이어 : 출력 뉴런 수 3개, 활성화 함수 ‘softmax’"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/team2/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/team2/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/team2/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/team2/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/team2/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/team2/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add( Conv2D( 32, kernel_size=(3,3), activation='relu', input_shape=(64,64,3) ) )\n",
    "model.add( MaxPooling2D( pool_size=(2,2) ) )\n",
    "model.add( Dropout(0.25) )\n",
    "\n",
    "model.add( Conv2D( 64, kernel_size=(3,3), activation='relu') )\n",
    "model.add( MaxPooling2D( pool_size=(2,2) ) )\n",
    "model.add( Dropout(0.25) )\n",
    "\n",
    "model.add( Flatten() )\n",
    "\n",
    "model.add( Dense(128, activation='relu') )\n",
    "model.add( Dropout(0.25) )\n",
    "\n",
    "model.add( Dense( len(lb.classes_), activation='softmax' ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 62, 62, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 31, 31, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 31, 31, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 29, 29, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 12544)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               1605760   \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 7)                 903       \n",
      "=================================================================\n",
      "Total params: 1,626,055\n",
      "Trainable params: 1,626,055\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 모델 구성 확인\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 모델 컴파일\n",
    "- [손실함수] \n",
    "- categorical_crossentropy 를 사용\n",
    "\n",
    "- [최적화 함수]\n",
    "- 1. 아담 \n",
    "    -> opt = Adam(lr=1e-3, decay=1e-3 / 50)\n",
    "- 2. SGD \n",
    "    -> opt = SGD(lr=1e-4, momentum=0.9, decay=1e-4 / args[\"epochs\"])\n",
    "- 3. rmsprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] compiling model...\n",
      "WARNING:tensorflow:From /home/team2/anaconda3/lib/python3.7/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/team2/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3295: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"[INFO] compiling model...\")\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer='rmsprop', metrics=['accuracy'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/team2/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Train on 1810 samples, validate on 453 samples\n",
      "Epoch 1/50\n",
      "1810/1810 [==============================] - 3s 1ms/step - loss: 1.9017 - acc: 0.4431 - val_loss: 1.3530 - val_acc: 0.5166\n",
      "Epoch 2/50\n",
      "1810/1810 [==============================] - 0s 226us/step - loss: 1.1832 - acc: 0.5624 - val_loss: 1.3588 - val_acc: 0.3731\n",
      "Epoch 3/50\n",
      "1810/1810 [==============================] - 0s 235us/step - loss: 1.0432 - acc: 0.5657 - val_loss: 1.1478 - val_acc: 0.5894\n",
      "Epoch 4/50\n",
      "1810/1810 [==============================] - 0s 243us/step - loss: 0.8666 - acc: 0.6204 - val_loss: 1.0392 - val_acc: 0.6446\n",
      "Epoch 5/50\n",
      "1810/1810 [==============================] - 0s 249us/step - loss: 0.7684 - acc: 0.6890 - val_loss: 1.2102 - val_acc: 0.5121\n",
      "Epoch 6/50\n",
      "1810/1810 [==============================] - 0s 255us/step - loss: 0.6894 - acc: 0.7381 - val_loss: 0.6639 - val_acc: 0.7307\n",
      "Epoch 7/50\n",
      "1810/1810 [==============================] - 0s 241us/step - loss: 0.5362 - acc: 0.8033 - val_loss: 0.7827 - val_acc: 0.6623\n",
      "Epoch 8/50\n",
      "1810/1810 [==============================] - 0s 253us/step - loss: 0.4860 - acc: 0.8243 - val_loss: 0.5599 - val_acc: 0.8124\n",
      "Epoch 9/50\n",
      "1810/1810 [==============================] - 0s 246us/step - loss: 0.4245 - acc: 0.8459 - val_loss: 0.4423 - val_acc: 0.8278\n",
      "Epoch 10/50\n",
      "1810/1810 [==============================] - 0s 225us/step - loss: 0.3596 - acc: 0.8619 - val_loss: 0.3536 - val_acc: 0.8742\n",
      "Epoch 11/50\n",
      "1810/1810 [==============================] - 0s 254us/step - loss: 0.3234 - acc: 0.8790 - val_loss: 0.3803 - val_acc: 0.8565\n",
      "Epoch 12/50\n",
      "1810/1810 [==============================] - 0s 240us/step - loss: 0.2629 - acc: 0.9055 - val_loss: 0.4652 - val_acc: 0.8499\n",
      "Epoch 13/50\n",
      "1810/1810 [==============================] - 0s 255us/step - loss: 0.2265 - acc: 0.9271 - val_loss: 0.2867 - val_acc: 0.8786\n",
      "Epoch 14/50\n",
      "1810/1810 [==============================] - 0s 261us/step - loss: 0.2274 - acc: 0.9127 - val_loss: 0.3422 - val_acc: 0.8565\n",
      "Epoch 15/50\n",
      "1810/1810 [==============================] - 0s 265us/step - loss: 0.1987 - acc: 0.9204 - val_loss: 0.2067 - val_acc: 0.9360\n",
      "Epoch 16/50\n",
      "1810/1810 [==============================] - 0s 257us/step - loss: 0.1487 - acc: 0.9486 - val_loss: 0.2461 - val_acc: 0.8940\n",
      "Epoch 17/50\n",
      "1810/1810 [==============================] - 0s 269us/step - loss: 0.1525 - acc: 0.9530 - val_loss: 0.4319 - val_acc: 0.8455\n",
      "Epoch 18/50\n",
      "1810/1810 [==============================] - 0s 236us/step - loss: 0.1413 - acc: 0.9514 - val_loss: 0.2648 - val_acc: 0.9029\n",
      "Epoch 19/50\n",
      "1810/1810 [==============================] - 0s 253us/step - loss: 0.1440 - acc: 0.9530 - val_loss: 0.3218 - val_acc: 0.8742\n",
      "Epoch 20/50\n",
      "1810/1810 [==============================] - 0s 257us/step - loss: 0.1165 - acc: 0.9586 - val_loss: 0.1945 - val_acc: 0.9382\n",
      "Epoch 21/50\n",
      "1810/1810 [==============================] - 1s 282us/step - loss: 0.0805 - acc: 0.9762 - val_loss: 0.2087 - val_acc: 0.9294\n",
      "Epoch 22/50\n",
      "1810/1810 [==============================] - 0s 244us/step - loss: 0.1287 - acc: 0.9536 - val_loss: 0.2697 - val_acc: 0.9051\n",
      "Epoch 23/50\n",
      "1810/1810 [==============================] - 1s 292us/step - loss: 0.0833 - acc: 0.9729 - val_loss: 0.5549 - val_acc: 0.7748\n",
      "Epoch 24/50\n",
      "1810/1810 [==============================] - 0s 271us/step - loss: 0.1033 - acc: 0.9696 - val_loss: 0.2023 - val_acc: 0.9360\n",
      "Epoch 25/50\n",
      "1810/1810 [==============================] - 0s 247us/step - loss: 0.0848 - acc: 0.9718 - val_loss: 0.1968 - val_acc: 0.9360\n",
      "Epoch 26/50\n",
      "1810/1810 [==============================] - 0s 257us/step - loss: 0.0717 - acc: 0.9785 - val_loss: 0.1923 - val_acc: 0.9426\n",
      "Epoch 27/50\n",
      "1810/1810 [==============================] - 0s 243us/step - loss: 0.0525 - acc: 0.9845 - val_loss: 0.2388 - val_acc: 0.9139\n",
      "Epoch 28/50\n",
      "1810/1810 [==============================] - 0s 244us/step - loss: 0.0575 - acc: 0.9829 - val_loss: 0.1522 - val_acc: 0.9581\n",
      "Epoch 29/50\n",
      "1810/1810 [==============================] - 0s 239us/step - loss: 0.0673 - acc: 0.9768 - val_loss: 0.1624 - val_acc: 0.9647\n",
      "Epoch 30/50\n",
      "1810/1810 [==============================] - 0s 238us/step - loss: 0.0468 - acc: 0.9856 - val_loss: 0.2107 - val_acc: 0.9183\n",
      "Epoch 31/50\n",
      "1810/1810 [==============================] - 0s 242us/step - loss: 0.0472 - acc: 0.9845 - val_loss: 0.1596 - val_acc: 0.9647\n",
      "Epoch 32/50\n",
      "1810/1810 [==============================] - 0s 236us/step - loss: 0.0882 - acc: 0.9707 - val_loss: 0.2138 - val_acc: 0.9205\n",
      "Epoch 33/50\n",
      "1810/1810 [==============================] - 0s 256us/step - loss: 0.0325 - acc: 0.9895 - val_loss: 0.1678 - val_acc: 0.9492\n",
      "Epoch 34/50\n",
      "1810/1810 [==============================] - 0s 253us/step - loss: 0.0641 - acc: 0.9768 - val_loss: 0.1614 - val_acc: 0.9603\n",
      "Epoch 35/50\n",
      "1810/1810 [==============================] - 0s 271us/step - loss: 0.0290 - acc: 0.9928 - val_loss: 0.1678 - val_acc: 0.9603\n",
      "Epoch 36/50\n",
      "1810/1810 [==============================] - 0s 268us/step - loss: 0.0425 - acc: 0.9884 - val_loss: 0.1669 - val_acc: 0.9492\n",
      "Epoch 37/50\n",
      "1810/1810 [==============================] - 0s 251us/step - loss: 0.0268 - acc: 0.9928 - val_loss: 0.2467 - val_acc: 0.9272\n",
      "Epoch 38/50\n",
      "1810/1810 [==============================] - 0s 239us/step - loss: 0.0317 - acc: 0.9884 - val_loss: 0.1752 - val_acc: 0.9647\n",
      "Epoch 39/50\n",
      "1810/1810 [==============================] - 0s 244us/step - loss: 0.0458 - acc: 0.9834 - val_loss: 0.1870 - val_acc: 0.9536\n",
      "Epoch 40/50\n",
      "1810/1810 [==============================] - 1s 280us/step - loss: 0.0216 - acc: 0.9939 - val_loss: 0.1796 - val_acc: 0.9536\n",
      "Epoch 41/50\n",
      "1810/1810 [==============================] - 0s 272us/step - loss: 0.0346 - acc: 0.9901 - val_loss: 0.1780 - val_acc: 0.9492\n",
      "Epoch 42/50\n",
      "1810/1810 [==============================] - 1s 288us/step - loss: 0.0230 - acc: 0.9939 - val_loss: 0.1824 - val_acc: 0.9514\n",
      "Epoch 43/50\n",
      "1810/1810 [==============================] - 0s 262us/step - loss: 0.0209 - acc: 0.9934 - val_loss: 0.2060 - val_acc: 0.9581\n",
      "Epoch 44/50\n",
      "1810/1810 [==============================] - 0s 253us/step - loss: 0.0336 - acc: 0.9901 - val_loss: 0.1796 - val_acc: 0.9492\n",
      "Epoch 45/50\n",
      "1810/1810 [==============================] - 0s 247us/step - loss: 0.0197 - acc: 0.9950 - val_loss: 0.1823 - val_acc: 0.9603\n",
      "Epoch 46/50\n",
      "1810/1810 [==============================] - 0s 253us/step - loss: 0.0365 - acc: 0.9867 - val_loss: 0.2370 - val_acc: 0.9360\n",
      "Epoch 47/50\n",
      "1810/1810 [==============================] - 0s 260us/step - loss: 0.0204 - acc: 0.9923 - val_loss: 0.2121 - val_acc: 0.9514\n",
      "Epoch 48/50\n",
      "1810/1810 [==============================] - 0s 244us/step - loss: 0.0217 - acc: 0.9934 - val_loss: 0.3793 - val_acc: 0.8830\n",
      "Epoch 49/50\n",
      "1810/1810 [==============================] - 0s 235us/step - loss: 0.0359 - acc: 0.9884 - val_loss: 0.1815 - val_acc: 0.9603\n",
      "Epoch 50/50\n",
      "1810/1810 [==============================] - 0s 238us/step - loss: 0.0102 - acc: 0.9972 - val_loss: 0.2034 - val_acc: 0.9492\n",
      "elapsed_time:25.25054168701172[sec]\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "# GPU 로 돌리기 (with 포함시킬것)\n",
    "with tf.device('/device:GPU:0'):\n",
    "    model.fit( trainX, trainY, batch_size=128, epochs= 50 , validation_split= 0.2 )\n",
    "    \n",
    "elapsed_time = time.time() - start\n",
    "print (\"elapsed_time:{}\".format(elapsed_time) + \"[sec]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] evaluating network...\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "             30       0.99      0.92      0.95       183\n",
      "             50       0.96      0.98      0.97       381\n",
      "             60       0.91      0.97      0.94       120\n",
      "      NO_U-turn       1.00      0.95      0.98        21\n",
      "        NO_left       0.97      1.00      0.98        30\n",
      "NO_parking_stop       1.00      1.00      1.00        15\n",
      "       NO_right       1.00      0.80      0.89         5\n",
      "\n",
      "       accuracy                           0.96       755\n",
      "      macro avg       0.98      0.95      0.96       755\n",
      "   weighted avg       0.96      0.96      0.96       755\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 모델 예측\n",
    "print(\"[INFO] evaluating network...\")\n",
    "predictions = model.predict(testX, batch_size=32)\n",
    "print(classification_report(testY.argmax(axis=1),\n",
    "                            predictions.argmax(axis=1), target_names=lb.classes_) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#모델을 JSON 파일 형식으로 만들어 저장하기\n",
    "model_json = model.to_json()\n",
    "with open(\"./model/model.json\", \"w\") as json_file : \n",
    "    json_file.write(model_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 가중치(weights) 저장\n",
    "model.save_weights('./model/model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 학습된 모델을 사용하여 ROI영역 레이블 예측 및 그리기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary packages\n",
    "from keras.models import load_model\n",
    "from collections import deque\n",
    "import numpy as np\n",
    "import argparse\n",
    "import pickle\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 독일 이미지로 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 1.]\n",
      "label text: NO_right\n"
     ]
    }
   ],
   "source": [
    "# 7가지 이미지 데이터 예측\n",
    "test_path_30 = './test_image/30_black.jpg'                             # 성공\n",
    "test_path_50 = './test_image/50_29.jpg'                                # 성공\n",
    "test_path_60 = './test_image/60_211.jpg'                              # 성공\n",
    "test_path_return = './test_image/test_no_return2.png'            # 성공\n",
    "test_path_no_left = './test_image/test_no_left.png'                # 성공\n",
    "test_path_no_right= './test_image/test_no_right.png'             # 실패 -> 배경이 검은색이라 예측실패인 걸로 예측됨\n",
    "test_path_no_right2= './test_image/test_no_parking.jpg'        # 성공\n",
    "test_path_no_parking = './test_image/test_no_parking.jpeg'   # 성공\n",
    "\n",
    "# 예측 테스트\n",
    "frame = cv2.imread(test_path_no_right2)\n",
    "frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "frame = cv2.resize(frame, (64, 64)).astype(\"float32\")\n",
    "\n",
    "# 예측\n",
    "preds = model.predict(np.expand_dims(frame, axis=0))[0]\n",
    "print(preds)\n",
    "\n",
    "# 레이블 표시\n",
    "label = lb.classes_[np.argmax(preds)]\n",
    "text = \"label text: {}\".format(label)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label : [0. 1. 0. 0. 0. 0. 0.]\n",
      "predict: 50\n"
     ]
    }
   ],
   "source": [
    "## ---------------------------------------------------------------------------------연경아 부탁해---------------------------------------------------------------------------------- ##\n",
    "# 전처리 과정을 거친 우리 데이터로 예측 테스트\n",
    "img = cv2.imread('./test_image/sample3_515.jpg')\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "blur = cv2.GaussianBlur(gray, (3, 3), 0)\n",
    "circles = cv2.HoughCircles(blur, cv2.HOUGH_GRADIENT, 1.5, 30, None, 570)\n",
    "\n",
    "#print(circles) # (x, y, 반지름)\n",
    "if circles is not None :\n",
    "    circles = np.uint16(np.around(circles))\n",
    "    for i in circles[0, :] :\n",
    "        x = i[0]\n",
    "        y = i[1]\n",
    "        r = i[2]\n",
    "        #print(x, y, r)\n",
    "        #print((x-r, y-r), (x+r, y+r))\n",
    "        cv2.circle(img, (i[0], i[1]), i[2], (0, 255, 0), 2)\n",
    "        cv2.circle(img, (i[0], i[1]), 2, (0, 0, 255), 5)\n",
    "        cv2.rectangle(img, (x-r, y-r), (x+r, y+r), (255, 0, 0), 1)\n",
    "      #x,y 원의 중심 좌표 / r : 반지름  \n",
    "frame = img[y-r:y+r, x-r:x+r]\n",
    "## -------------------------------------------------------------------------------------화이팅-------------------------------------------------------------------------------------------- ##\n",
    "\n",
    "\n",
    "frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "frame = cv2.resize(frame, (64, 64)).astype(\"float32\")\n",
    "\n",
    "# 예측 후 , roi 영역 표시\n",
    "preds = model.predict(np.expand_dims(frame, axis=0))[0]\n",
    "print('label : {}'.format(preds))\n",
    "\n",
    "#  레이블 확인\n",
    "label = lb.classes_[np.argmax(preds)]\n",
    "text = \"predict: {}\".format(label)\n",
    "print(text)\n",
    "cv2.putText(img, text, (x-50, y-50), cv2.FONT_HERSHEY_SIMPLEX, 1.25, (0, 255, 0), 5)\n",
    "\n",
    "# 이미지 확인\n",
    "cv2.imshow('final', img)\n",
    "\n",
    "# 종료 : 키보드 클릭\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 영상파일 예측 텍스트 첨부"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary packages\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from keras.models import load_model\n",
    "import numpy as np\n",
    "import pickle\n",
    "import cv2\n",
    "#저장된 JSON 파일로 부터 모델 로드하기\n",
    "from keras.models import model_from_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_file = open(\"./model/model.json\", \"r\")\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk\n"
     ]
    }
   ],
   "source": [
    "#로드한 모델에 Weight 로드하기\n",
    "loaded_model.load_weights(\"./model/model.h5\")\n",
    "print(\"Loaded model from disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#모델 컴파일 후 Evaluation\n",
    "loaded_model.compile(loss=\"categorical_crossentropy\", optimizer=\"rmsprop\", metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 30\n",
      "predict: 30\n",
      "predict: 30\n",
      "predict: 30\n",
      "predict: 30\n",
      "predict: 30\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: NO_left\n",
      "predict: NO_left\n",
      "predict: NO_left\n",
      "predict: 50\n",
      "predict: 60\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 30\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 30\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 30\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 30\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 30\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 30\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 30\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 30\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 30\n",
      "predict: 30\n",
      "predict: 30\n",
      "predict: 30\n",
      "predict: 30\n",
      "predict: 30\n",
      "predict: 30\n",
      "predict: 30\n",
      "predict: 30\n",
      "predict: 30\n",
      "predict: 50\n",
      "predict: 30\n",
      "predict: 30\n",
      "predict: 30\n",
      "predict: 30\n",
      "predict: 30\n",
      "predict: 30\n",
      "predict: 30\n",
      "predict: 30\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 30\n",
      "predict: 30\n",
      "predict: 30\n",
      "predict: 30\n",
      "predict: 30\n",
      "predict: 50\n",
      "predict: 30\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 30\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 30\n",
      "predict: 30\n",
      "predict: 30\n",
      "predict: 30\n",
      "predict: 30\n",
      "predict: 30\n",
      "predict: 30\n",
      "predict: 30\n",
      "predict: 30\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 30\n",
      "predict: 30\n",
      "predict: 30\n",
      "predict: 30\n",
      "predict: 30\n",
      "predict: 30\n",
      "predict: 30\n",
      "predict: 30\n",
      "predict: 30\n",
      "predict: 30\n",
      "predict: 30\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 30\n",
      "predict: 30\n",
      "predict: 30\n",
      "predict: 30\n",
      "predict: 30\n",
      "predict: 30\n",
      "predict: 30\n",
      "predict: 30\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 30\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 30\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 60\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 60\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 60\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 60\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 30\n",
      "predict: 30\n",
      "predict: 30\n",
      "predict: 30\n",
      "predict: 30\n",
      "predict: 30\n",
      "predict: 30\n",
      "predict: 30\n",
      "predict: 30\n",
      "predict: 30\n",
      "predict: 30\n",
      "predict: 30\n",
      "predict: 30\n",
      "predict: 30\n",
      "predict: 30\n",
      "predict: 30\n",
      "predict: 30\n",
      "predict: 30\n",
      "predict: 30\n",
      "predict: 30\n",
      "predict: 30\n",
      "predict: 30\n",
      "predict: 30\n",
      "predict: 30\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 60\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 30\n",
      "predict: 30\n",
      "predict: 30\n",
      "predict: 30\n",
      "predict: 30\n",
      "predict: 30\n",
      "predict: 30\n",
      "predict: 30\n",
      "predict: 30\n",
      "predict: 30\n",
      "predict: 30\n",
      "predict: 30\n",
      "predict: 30\n",
      "predict: 30\n",
      "predict: 30\n",
      "predict: 30\n",
      "predict: 30\n",
      "predict: 30\n",
      "predict: 30\n",
      "predict: 30\n",
      "predict: 30\n",
      "predict: 30\n",
      "predict: 30\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 60\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 30\n",
      "predict: 30\n",
      "predict: 30\n",
      "predict: 30\n",
      "predict: 30\n",
      "predict: 30\n",
      "predict: 30\n",
      "predict: 30\n",
      "predict: 30\n",
      "predict: 30\n",
      "predict: 30\n",
      "predict: 30\n",
      "predict: 30\n",
      "predict: 30\n",
      "predict: 30\n",
      "predict: 30\n",
      "predict: 30\n",
      "predict: 30\n",
      "predict: 30\n",
      "predict: 30\n",
      "predict: 30\n",
      "predict: 30\n",
      "predict: 30\n",
      "predict: 30\n",
      "predict: 30\n",
      "predict: 30\n",
      "predict: 30\n",
      "predict: 30\n",
      "predict: 30\n",
      "predict: 30\n",
      "predict: 30\n",
      "predict: 30\n",
      "predict: 30\n",
      "predict: 30\n",
      "predict: 30\n",
      "predict: 50\n",
      "predict: 30\n",
      "predict: 30\n",
      "predict: 30\n",
      "predict: 30\n",
      "predict: 30\n",
      "predict: 30\n",
      "predict: 30\n",
      "predict: 30\n",
      "predict: 30\n",
      "predict: 30\n",
      "predict: 30\n",
      "predict: 30\n",
      "predict: 30\n",
      "predict: 30\n",
      "predict: 30\n",
      "predict: 30\n",
      "predict: 30\n",
      "predict: 30\n",
      "predict: 30\n",
      "predict: 30\n",
      "predict: 30\n",
      "predict: 30\n",
      "predict: 30\n",
      "predict: 30\n",
      "predict: 30\n",
      "predict: 30\n",
      "predict: 30\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: NO_right\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: NO_right\n",
      "predict: NO_right\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: NO_right\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 30\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n",
      "predict: 50\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "OpenCV(3.4.7) /io/opencv/modules/imgproc/src/color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cvtColor'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-9921ccca5d33>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m                             \u001b[0;31m#print(frame.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m                             \u001b[0mframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOLOR_BGR2RGB\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m                             \u001b[0mframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m                             \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31merror\u001b[0m: OpenCV(3.4.7) /io/opencv/modules/imgproc/src/color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cvtColor'\n"
     ]
    }
   ],
   "source": [
    "#video_path = './video/video1.mp4'\n",
    "video_path = './video/test.mp4'\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "video_file = video_path.split('/')[-1]\n",
    "video_name = video_file.split('.')[0]\n",
    "\n",
    "if cap.isOpened() :\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    delay = int(1000/fps)\n",
    "    print(delay) # 33\n",
    "\n",
    "## ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- ## \n",
    "    while True :\n",
    "        ret, img = cap.read()                      # 다음 프레임 읽기\n",
    "        \n",
    "        if ret :                                           # 프레임 읽기 정상 \n",
    "## ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- ## \n",
    "            img2 = img.copy()\n",
    "            h, w = img.shape[:2]\n",
    "           \n",
    "            # HSV 영상으로 변환\n",
    "            hsv = cv2.cvtColor(img2, cv2.COLOR_BGR2HSV)\n",
    "            img2 = cv2.bilateralFilter(img, 9, 105, 105)\n",
    "            r, g, b = cv2.split(img2)\n",
    "            equalize1= cv2.equalizeHist(r)\n",
    "            equalize2= cv2.equalizeHist(g)\n",
    "            equalize3= cv2.equalizeHist(b)\n",
    "            equalize = cv2.merge((equalize1, equalize2, equalize3))\n",
    "            img2 = equalize\n",
    "\n",
    "            # 색상별 영역 지정\n",
    "            red1 = np.array([0, 50, 50])\n",
    "            red2 = np.array([15, 255, 255])\n",
    "            red3 = np.array([165, 50, 50])\n",
    "            red4 = np.array([180, 255, 255])\n",
    "\n",
    "            # 색상에 따른 마스크 생성\n",
    "            mask_red1 = cv2.inRange(hsv, red1, red2)\n",
    "            mask_red2 = cv2.inRange(hsv, red3, red4)\n",
    "            mask_red = mask_red1 + mask_red2\n",
    "\n",
    "            numOfLabels, img_label, stats, centroids = cv2.connectedComponentsWithStats(mask_red2)\n",
    "            \n",
    "            for idx, centroid in enumerate(centroids) :\n",
    "                if stats[idx][0] == 0 and stats[idx][1] == 0 :\n",
    "                    continue\n",
    "\n",
    "                if np.any(np.isnan(centroid)) :\n",
    "                    continue\n",
    "\n",
    "                x, y, w, h, area = stats[idx]\n",
    "                centerX, centerY = int(centroid[0]), int(centroid[1])\n",
    "\n",
    "                if area > 50 and abs(w-h) < 5 : \n",
    "                    # 원 검출\n",
    "                    detected_img = img2[y:y+h, x:x+w]\n",
    "                    gray_detected_img = cv2.cvtColor(detected_img, cv2.COLOR_BGR2GRAY)\n",
    "                    gray_detected_img = cv2.resize(gray_detected_img, (gray_detected_img.shape[1]*5, gray_detected_img.shape[0]*5))\n",
    "                    circles = cv2.HoughCircles(gray_detected_img, cv2.HOUGH_GRADIENT, 1, 100, param1=50, param2=30, minRadius=10, maxRadius=0)\n",
    "                    if circles is not None :\n",
    "                        circles = np.uint16(np.around(circles))\n",
    "                        #print('circles.shape : {}'.format(circles.shape))\n",
    "                        #print(circles)\n",
    "                        for i in circles[0, :] :\n",
    "                            #벗어나는 경우 예외처리 필요함\n",
    "                            frame = img[ y-3 : y+h+3 , x-3 : x+w+3 ]\n",
    "                            #print('i : {}'.format(i) )\n",
    "                            # x,y -> 좌표 / w,h -> 너비 , 높이\n",
    "                            #cv2.imshow(video_file, frame)        # 화면에 표시\n",
    "#                             if cv2.waitKey(0) == 27:\n",
    "#                                 continue\n",
    "                                \n",
    "#                             if cv2.waitKey(0) & 0xFF == ord('q'):\n",
    "#                                 break\n",
    "                            # 예측 후 , roi 영역 표시\n",
    "                            \n",
    "                            #print(frame.shape)\n",
    "                            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "                            frame = cv2.resize(frame, (64, 64) )\n",
    "                            preds = model.predict(np.expand_dims(frame, axis=0))[0]\n",
    "                            #print('label : {}'.format(preds))\n",
    "\n",
    "                            #  레이블 확인\n",
    "                            label = lb.classes_[np.argmax(preds)]\n",
    "                            text = \"predict: {}\".format(label)\n",
    "                            print(text)\n",
    "                            cv2.putText( img, text, ( x + 50, y + 50 ), cv2.FONT_HERSHEY_SIMPLEX, 1.0, (0, 255, 0), 5)\n",
    "                            cv2.rectangle(img, (x-3, y-3), (x+w+3, y+h+3), (255, 0, 0), 1)\n",
    "## ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- ##           \n",
    "            \n",
    "            \n",
    "    \n",
    "            cv2.imshow('video_file', img)        # 화면에 표시\n",
    "            cv2.waitKey(delay)                     # fps에 맞게 시간 지연\n",
    "        else :\n",
    "            break\n",
    "else :\n",
    "    print(\"can't open video.\")\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "keras-gpu",
   "language": "python",
   "name": "py374"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
