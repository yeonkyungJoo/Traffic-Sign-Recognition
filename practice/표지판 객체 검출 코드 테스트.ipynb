{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[117 117 117 ... 123 123 123]\n",
      " [117 117 117 ... 123 123 123]\n",
      " [117 117 117 ... 123 123 123]\n",
      " ...\n",
      " [127 127 127 ... 122 122 122]\n",
      " [127 127 127 ... 121 121 121]\n",
      " [127 127 127 ... 121 121 121]]\n",
      "125.0\n"
     ]
    }
   ],
   "source": [
    "img = cv2.imread('./sample1.jpg')\n",
    "img = cv2.resize(img, (img.shape[1]//2, img.shape[0]//2))\n",
    "img_yuv = cv2.cvtColor(img, cv2.COLOR_BGR2YUV)\n",
    "\n",
    "cv2.imshow('img', img)\n",
    "cv2.imshow('img_yuv', img_yuv)\n",
    "\n",
    "# cv2.imshow('img_yuv[:, :, 0]', img_yuv[:, :, 0])\n",
    "# cv2.imshow('img_yuv[:, :, 1]', img_yuv[:, :, 1])\n",
    "# cv2.imshow('img_yuv[:, :, 2]', img_yuv[:, :, 2])\n",
    "img2 = img_yuv[:, :, 2]\n",
    "print(img2)\n",
    "# thr, mask1 = cv2.threshold(img2, 127, 1, cv2.THRESH_BINARY)\n",
    "# print(thr)\n",
    "# cv2.imshow('mask1', mask1)\n",
    "\n",
    "# thr, mask2 = cv2.threshold(img2, 127, 1, cv2.THRESH_BINARY_INV)\n",
    "# cv2.imshow('mask2', mask2)\n",
    "\n",
    "thr, mask3 = cv2.threshold(img2, 127, 255, cv2.THRESH_BINARY)\n",
    "cv2.imshow('mask3', mask3)\n",
    "\n",
    "t, t_otsu = cv2.threshold(img2, -1, 255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)\n",
    "cv2.imshow('t_otsu', t_otsu)\n",
    "print(t)\n",
    "# adapt_mask = cv2.adaptiveThreshold(img2, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY_INV, 11, 10)\n",
    "# cv2.imshow('adapt_mask', adapt_mask)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "img = cv2.imread('./sample1.jpg')[:, :, 0]\n",
    "\n",
    "img = cv2.resize(img, (img.shape[1]//2, img.shape[0]//2))\n",
    "cv2.imshow('img', img)\n",
    "\n",
    "thr, mask3 = cv2.threshold(img, 200, 255, cv2.THRESH_BINARY_INV)\n",
    "cv2.imshow('mask3', mask3)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "img = cv2.imread('./sample1.jpg')\n",
    "img = cv2.resize(img, (img.shape[1]//2, img.shape[0]//2))\n",
    "img_yuv = cv2.cvtColor(img, cv2.COLOR_BGR2YUV)\n",
    "\n",
    "# cv2.imshow('img', img)\n",
    "# cv2.imshow('img_yuv', img_yuv)\n",
    "img2 = img_yuv[:, :, 2]\n",
    "# cv2.imshow('img2', img2)\n",
    "# print(img2)\n",
    "\n",
    "img3 = img_yuv[:, :, 0]\n",
    "cv2.imshow('img3', img3)\n",
    "# print(img2)\n",
    "\n",
    "# 필터 커널 세팅\n",
    "kernel = np.ones((1, 1), np.uint8)\n",
    "kernel2 = np.ones((4, 4), np.uint8)\n",
    "\n",
    "thr, mask3 = cv2.threshold(img2, 200, 255, cv2.THRESH_BINARY)\n",
    "cv2.imshow('mask3', mask3)\n",
    "erosion_image = cv2.erode(mask3, kernel, iterations=1)  \n",
    "dilation_image = cv2.dilate(erosion_image, kernel2, iterations=1) \n",
    "cv2.imshow('dilation_image', dilation_image)\n",
    "\n",
    "# 블록 사이즈\n",
    "blk_size = 9\n",
    "# 차감 상수\n",
    "C = 5\n",
    "\n",
    "# 오츠의 알고리즘으로 단일 경계값을 전체 이미지에 적용\n",
    "# ret, th1 = cv2.threshold(img, 0, 255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)\n",
    "\n",
    "# 적응형 스레시홀드를 평균과 가우시안 분포로 각각 적용\n",
    "# th2 = cv2.adaptiveThreshold(img2, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, blk_size, C)\n",
    "# th3 = cv2.adaptiveThreshold(img2, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, blk_size, C)\n",
    "# cv2.imshow('th2', th2)\n",
    "# cv2.imshow('th3', th3)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.1.1) C:\\projects\\opencv-python\\opencv\\modules\\imgproc\\src\\thresh.cpp:1645: error: (-215:Assertion failed) src.type() == CV_8UC1 in function 'cv::adaptiveThreshold'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-64-c563f25e70b6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mhsv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCOLOR_BGR2HSV\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0madapt_mask\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madaptiveThreshold\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhsv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m255\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mADAPTIVE_THRESH_MEAN_C\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTHRESH_BINARY_INV\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m11\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m# print(hsv[0][np.argmax(hsv[0], axis = 0)])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.1.1) C:\\projects\\opencv-python\\opencv\\modules\\imgproc\\src\\thresh.cpp:1645: error: (-215:Assertion failed) src.type() == CV_8UC1 in function 'cv::adaptiveThreshold'\n"
     ]
    }
   ],
   "source": [
    "img = cv2.imread('./color.PNG')\n",
    "\n",
    "hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV )\n",
    "\n",
    "# print(hsv[0][np.argmax(hsv[0], axis = 0)])\n",
    "# print(hsv[0][np.argmin(hsv[0], axis = 0)])\n",
    "# print(hsv[1][np.argmax(hsv[1], axis = 0)])\n",
    "# print(hsv[1][np.argmin(hsv[1], axis = 0)])\n",
    "# print(hsv[2][np.argmax(hsv[2], axis = 0)])\n",
    "# print(hsv[2][np.argmin(hsv[2], axis = 0)])\n",
    "cv2.imshow('hsv', hsv)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 필터 커널 세팅\n",
    "kernel = np.ones((1, 1), np.uint8)\n",
    "kernel2 = np.ones((3, 3), np.uint8)\n",
    "\n",
    "# 필터 \n",
    "red1 = np.array([0, 50, 0]) # 밝은 빨강(주황계열)\n",
    "red2 = np.array([5, 250, 240])\n",
    "\n",
    "# Hue : 0~180\n",
    "# Saturation : 0~255\n",
    "# Value : 0~255\n",
    "\n",
    "red3 = np.array([165, 50, 0]) # 어두운 빨강(갈색계열)\n",
    "red4 = np.array([175, 250, 240])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# red1 = np.array([0, 30, 100]) # 밝은 빨강(주황계열)\n",
    "# red2 = np.array([5, 150, 200])\n",
    "\n",
    "# red3 = np.array([155, 30, 100]) # 어두운 빨강(갈색계열)\n",
    "# red4 = np.array([180, 150, 200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "red1 = np.array([0, 30, 0]) # 밝은 빨강(주황계열)\n",
    "red2 = np.array([5, 250, 240])\n",
    "\n",
    "red3 = np.array([155, 50, 0]) # 어두운 빨강(갈색계열)\n",
    "red4 = np.array([180, 250, 240])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('./frame1.PNG')\n",
    "img = cv2.resize(img, (img.shape[1]//2, img.shape[0]//2))\n",
    "\n",
    "cv2.imshow('img', img)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (388, 836, 3)\n",
    "roi = img[0:int(img.shape[0]*0.8), :, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('roi', roi)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = np.ones((1, 1), np.uint8)\n",
    "kernel2 = np.ones((4, 4), np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-6a42de0492db>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m     \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m//\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m//\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m     \u001b[1;31m# roi = img[0:int(img.shape[0]*0.8), :, :]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[1;31m# blur = cv2.GaussianBlur( img, (3,3), 0 )\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "# 영상 경로 설정\n",
    "video_path= './video1.mp4'\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "# 영상 이름\n",
    "video_file = video_path.split('/')[-1]\n",
    "video_name = video_file.split('.')[0]\n",
    "\n",
    "while True :\n",
    "    # 영상 읽기\n",
    "    ret, img = cap.read()\n",
    "    \n",
    "    # 마지막 프레임 확인\n",
    "    if ret is None:\n",
    "        break\n",
    "        \n",
    "    img = cv2.resize(img, (img.shape[1]//2, img.shape[0]//2))\n",
    "    # roi = img[0:int(img.shape[0]*0.8), :, :]\n",
    "    # blur = cv2.GaussianBlur( img, (3,3), 0 )    \n",
    "    # hsv = cv2.cvtColor( blur, cv2.COLOR_BGR2HSV )\n",
    "    \n",
    "    # 색상에 따른 마스크 생성\n",
    "    # mask_red1 = cv2.inRange(hsv, red1, red2)\n",
    "    # mask_red2 = cv2.inRange(hsv, red3, red4)\n",
    "    \n",
    "    # 마스크 결합\n",
    "    # mask_red = mask_red1 + mask_red2\n",
    "    # thr, mask_red = cv2.threshold(mask_red, 235, 1, cv2.THRESH_BINARY)\n",
    "\n",
    "    # mask_red = cv2.adaptiveThreshold(mask_red, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, 11, 10)\n",
    "\n",
    "    \n",
    "    yuv = cv2.cvtColor(img, cv2.COLOR_BGR2YUV)\n",
    "    img2 = yuv[:, :, 2]\n",
    "\n",
    "    thr, mask_red = cv2.threshold(img2, 150, 255, cv2.THRESH_BINARY)\n",
    "    \n",
    "    # 침식 (노이즈제거) -> 팽창(픽셀 살리기)\n",
    "    erosion_mask = cv2.erode(mask_red, kernel, iterations=1)\n",
    "    # cv2.imshow('erosion_mask', erosion_mask)\n",
    "    dilation_mask = cv2.dilate(erosion_mask, kernel2, iterations=1) \n",
    "    # cv2.imshow('dilation_mask', dilation_mask)\n",
    "    \n",
    "    contours, hierarchy = cv2.findContours(dilation_mask, cv2.RETR_CCOMP, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    mask_external = np.zeros(dilation_mask.shape, dilation_mask.dtype)\n",
    "    for i in range(len(contours)) :\n",
    "        if hierarchy[0][i][3] == -1 :\n",
    "            cv2.drawContours(mask_external, contours, i, 255, -1)\n",
    "\n",
    "        \n",
    "    mask_internal = np.zeros(dilation_mask.shape, dilation_mask.dtype)\n",
    "    for i in range(len(contours)) :\n",
    "        if hierarchy[0][i][3] != -1 :\n",
    "            cv2.drawContours(mask_internal, contours, i, 255, -1)\n",
    "                    \n",
    "    _, _, stats_i, centroids_i = cv2.connectedComponentsWithStats(mask_internal)\n",
    "    _, _, stats_e, centroids_e = cv2.connectedComponentsWithStats(mask_external)\n",
    "    \n",
    "    for idx, centroid in enumerate(centroids) :\n",
    "        \n",
    "        if stats[idx][0] == 0 and stats[idx][1] == 0 :\n",
    "            continue\n",
    "        if np.any(np.isnan(centroid)) :\n",
    "            continue\n",
    "\n",
    "        x, y, w, h, area = stats[idx]\n",
    "        centerX, centerY = int(centroid[0]), int(centroid[1])\n",
    "\n",
    "        if area > 120 and abs(w-h) < 5 :\n",
    "            # cv2.rectangle(img, (x-10, y-10), (x+w+10, y+h+10), (0, 0, 255), 2)\n",
    "            # cv2.circle(img, ( centerX, centerY ), 2, (0, 255, 0), 2)\n",
    "            # print(x, y, w, h, area)\n",
    "\n",
    "#             detected_img = img[y-10 : y+h+10,  x-10 : x+w+10]\n",
    "#             gray_detected_img = cv2.cvtColor(detected_img, cv2.COLOR_BGR2GRAY)\n",
    "#             circles = cv2.HoughCircles(gray_detected_img, cv2.HOUGH_GRADIENT, 1, 100, param1=200, param2=30, minRadius=0, maxRadius=0)\n",
    "#             if circles is not None :\n",
    "#                 circles = np.uint16(np.around(circles))\n",
    "\n",
    "#                 for i in circles[0, :] :\n",
    "#                     cv2.circle(img, ( centerX, centerY ), 2, (0, 255, 0), 2)\n",
    "#                     cv2.rectangle(img, (x-10, y-10), (x+w+10, y+h+10), (0, 0, 255), 2)\n",
    "                \n",
    "            try : \n",
    "                detected_img = img[y-10 : y+h+10,  x-10 : x+w+10]\n",
    "                gray_detected_img = cv2.cvtColor(detected_img, cv2.COLOR_BGR2GRAY)\n",
    "                circles = cv2.HoughCircles(gray_detected_img, cv2.HOUGH_GRADIENT, 1, 100, param1=100, param2=30)\n",
    "                if circles is not None :\n",
    "                    circles = np.uint16(np.around(circles))\n",
    "\n",
    "                    for i in circles[0, :] :\n",
    "                        cv2.circle(img, ( centerX, centerY ), 2, (0, 255, 0), 2)\n",
    "                        cv2.rectangle(img, (x-10, y-10), (x+w+10, y+h+10), (0, 0, 255), 2)\n",
    "            except : \n",
    "                continue\n",
    "\n",
    "    cv2.imshow('img', img)\n",
    "    cv2.imshow('mask_internal', mask_internal)\n",
    "\n",
    "    if cv2.waitKey(1) == 27 :\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-8488fa095901>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m     \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m//\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m//\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m     \u001b[1;31m# roi = img[0:int(img.shape[0]*0.8), :, :]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[1;31m# blur = cv2.GaussianBlur( img, (3,3), 0 )\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "# 영상 경로 설정\n",
    "video_path= './video10.mp4'\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "# 영상 이름\n",
    "video_file = video_path.split('/')[-1]\n",
    "video_name = video_file.split('.')[0]\n",
    "\n",
    "while True :\n",
    "    # 영상 읽기\n",
    "    ret, img = cap.read()\n",
    "    \n",
    "    # 마지막 프레임 확인\n",
    "    if ret is None:\n",
    "        break\n",
    "        \n",
    "    img = cv2.resize(img, (img.shape[1]//2, img.shape[0]//2))\n",
    "    # roi = img[0:int(img.shape[0]*0.8), :, :]\n",
    "    # blur = cv2.GaussianBlur( img, (3,3), 0 )    \n",
    "    # hsv = cv2.cvtColor( blur, cv2.COLOR_BGR2HSV )\n",
    "    \n",
    "    # 색상에 따른 마스크 생성\n",
    "    # mask_red1 = cv2.inRange(hsv, red1, red2)\n",
    "    # mask_red2 = cv2.inRange(hsv, red3, red4)\n",
    "    \n",
    "    # 마스크 결합\n",
    "    # mask_red = mask_red1 + mask_red2\n",
    "    # thr, mask_red = cv2.threshold(mask_red, 235, 1, cv2.THRESH_BINARY)\n",
    "\n",
    "    # mask_red = cv2.adaptiveThreshold(mask_red, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, 11, 10)\n",
    "\n",
    "    \n",
    "    yuv = cv2.cvtColor(img, cv2.COLOR_BGR2YUV)\n",
    "    img2 = yuv[:, :, 2]\n",
    "\n",
    "    thr, mask_red = cv2.threshold(img2, 150, 255, cv2.THRESH_BINARY)\n",
    "    \n",
    "    # 침식 (노이즈제거) -> 팽창(픽셀 살리기)\n",
    "    erosion_mask = cv2.erode(mask_red, kernel, iterations=1)\n",
    "    # cv2.imshow('erosion_mask', erosion_mask)\n",
    "    dilation_mask = cv2.dilate(erosion_mask, kernel2, iterations=1) \n",
    "    # cv2.imshow('dilation_mask', dilation_mask)\n",
    "    \n",
    "    contours, hierarchy = cv2.findContours(dilation_mask, cv2.RETR_CCOMP, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    mask_external = np.zeros(dilation_mask.shape, dilation_mask.dtype)\n",
    "    for i in range(len(contours)) :\n",
    "        if hierarchy[0][i][3] == -1 :\n",
    "            cv2.drawContours(mask_external, contours, i, 255, -1)\n",
    "\n",
    "        \n",
    "    mask_internal = np.zeros(dilation_mask.shape, dilation_mask.dtype)\n",
    "    for i in range(len(contours)) :\n",
    "        if hierarchy[0][i][3] != -1 :\n",
    "            cv2.drawContours(mask_internal, contours, i, 255, -1)\n",
    "                    \n",
    "    _, _, stats_i, centroids_i = cv2.connectedComponentsWithStats(mask_internal)\n",
    "    _, _, stats_e, centroids_e = cv2.connectedComponentsWithStats(mask_external)\n",
    "    \n",
    "    for idx, centroid_i in enumerate(centroids_i) :\n",
    "        \n",
    "        if stats_i[idx][0] == 0 and stats_i[idx][1] == 0 :\n",
    "            continue\n",
    "        if np.any(np.isnan(centroid_i)) :\n",
    "            continue\n",
    "            \n",
    "        for centroid_e in centroids_e :\n",
    "            if abs(centroid_i[0] - centroid_e[0]) < 3 and abs(centroid_i[1] - centroid_e[1]) < 3 :\n",
    "                x, y, w, h, area = stats_i[idx]\n",
    "                centerX, centerY = int(centroid_i[0]), int(centroid_i[1])\n",
    "\n",
    "                if area > 120 and abs(w-h) < 5 :\n",
    "            # cv2.rectangle(img, (x-10, y-10), (x+w+10, y+h+10), (0, 0, 255), 2)\n",
    "            # cv2.circle(img, ( centerX, centerY ), 2, (0, 255, 0), 2)\n",
    "            # print(x, y, w, h, area)\n",
    "\n",
    "#             detected_img = img[y-10 : y+h+10,  x-10 : x+w+10]\n",
    "#             gray_detected_img = cv2.cvtColor(detected_img, cv2.COLOR_BGR2GRAY)\n",
    "#             circles = cv2.HoughCircles(gray_detected_img, cv2.HOUGH_GRADIENT, 1, 100, param1=200, param2=30, minRadius=0, maxRadius=0)\n",
    "#             if circles is not None :\n",
    "#                 circles = np.uint16(np.around(circles))\n",
    "\n",
    "#                 for i in circles[0, :] :\n",
    "#                     cv2.circle(img, ( centerX, centerY ), 2, (0, 255, 0), 2)\n",
    "#                     cv2.rectangle(img, (x-10, y-10), (x+w+10, y+h+10), (0, 0, 255), 2)\n",
    "                \n",
    "                    try : \n",
    "                        detected_img = img[y-10 : y+h+10,  x-10 : x+w+10]\n",
    "                        gray_detected_img = cv2.cvtColor(detected_img, cv2.COLOR_BGR2GRAY)\n",
    "                        circles = cv2.HoughCircles(gray_detected_img, cv2.HOUGH_GRADIENT, 1, 100, param1=100, param2=30)\n",
    "                        if circles is not None :\n",
    "                            circles = np.uint16(np.around(circles))\n",
    "\n",
    "                            for i in circles[0, :] :\n",
    "                                cv2.circle(img, ( centerX, centerY ), 2, (0, 255, 0), 2)\n",
    "                                cv2.rectangle(img, (x-10, y-10), (x+w+10, y+h+10), (0, 0, 255), 2)\n",
    "                    except : \n",
    "                        continue\n",
    "\n",
    "    cv2.imshow('img', img)\n",
    "#     cv2.imshow('mask_internal', mask_internal)\n",
    "#     cv2.imshow('mask_external', mask_external)\n",
    "    if cv2.waitKey(1) == 27 :\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-0e1cb8201c82>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     19\u001b[0m         \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m     \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m//\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m//\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m     \u001b[0myuv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCOLOR_BGR2YUV\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m     \u001b[0mimg2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0myuv\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "############################################################################################################\n",
    "    # 마지막 코드 #\n",
    "############################################################################################################\n",
    "\n",
    "# 영상 경로 설정\n",
    "video_path= './video1.mp4'\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "# 영상 이름\n",
    "video_file = video_path.split('/')[-1]\n",
    "video_name = video_file.split('.')[0]\n",
    "\n",
    "while True :\n",
    "    # 영상 읽기\n",
    "    ret, img = cap.read()\n",
    "    \n",
    "    # 마지막 프레임 확인\n",
    "    if ret is None:\n",
    "        break\n",
    "        \n",
    "    img = cv2.resize(img, (img.shape[1]//2, img.shape[0]//2))    \n",
    "    yuv = cv2.cvtColor(img, cv2.COLOR_BGR2YUV)\n",
    "    img2 = yuv[:, :, 2]\n",
    "\n",
    "    thr, mask_red = cv2.threshold(img2, 140, 255, cv2.THRESH_BINARY)\n",
    "    \n",
    "    # 침식 (노이즈제거) -> 팽창(픽셀 살리기)\n",
    "    erosion_mask = cv2.erode(mask_red, kernel, iterations=1)\n",
    "    dilation_mask = cv2.dilate(erosion_mask, kernel2, iterations=1) \n",
    "    \n",
    "    contours, hierarchy = cv2.findContours(dilation_mask, cv2.RETR_CCOMP, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    mask_external = np.zeros(dilation_mask.shape, dilation_mask.dtype)\n",
    "    for i in range(len(contours)) :\n",
    "        if hierarchy[0][i][3] == -1 :\n",
    "            cv2.drawContours(mask_external, contours, i, 255, -1)\n",
    "\n",
    "    mask_internal = np.zeros(dilation_mask.shape, dilation_mask.dtype)\n",
    "    for i in range(len(contours)) :\n",
    "        if hierarchy[0][i][3] != -1 :\n",
    "            cv2.drawContours(mask_internal, contours, i, 255, -1)\n",
    "                    \n",
    "    _, _, stats_i, centroids_i = cv2.connectedComponentsWithStats(mask_internal)\n",
    "    _, _, stats_e, centroids_e = cv2.connectedComponentsWithStats(mask_external)\n",
    "    \n",
    "    for idx, centroid_i in enumerate(centroids_i) :\n",
    "        \n",
    "        if stats_i[idx][0] == 0 and stats_i[idx][1] == 0 :\n",
    "            continue\n",
    "        if np.any(np.isnan(centroid_i)) :\n",
    "            continue\n",
    "            \n",
    "        for centroid_e in centroids_e :\n",
    "            if abs(centroid_i[0] - centroid_e[0]) < 3 and abs(centroid_i[1] - centroid_e[1]) < 3 :\n",
    "                x, y, w, h, area = stats_i[idx]\n",
    "                centerX, centerY = int(centroid_i[0]), int(centroid_i[1])\n",
    "\n",
    "                if area > 120 and abs(w-h) < 5 :\n",
    "                    try : \n",
    "                        detected_img = img[y-10 : y+h+10,  x-10 : x+w+10]\n",
    "                        gray_detected_img = cv2.cvtColor(detected_img, cv2.COLOR_BGR2GRAY)\n",
    "                        circles = cv2.HoughCircles(gray_detected_img, cv2.HOUGH_GRADIENT, 1, 100, param1=100, param2=30)\n",
    "                        if circles is not None :\n",
    "                            circles = np.uint16(np.around(circles))\n",
    "\n",
    "                            for i in circles[0, :] :\n",
    "                                cv2.circle(img, ( centerX, centerY ), 2, (0, 255, 0), 2)\n",
    "                                cv2.rectangle(img, (x-10, y-10), (x+w+10, y+h+10), (0, 0, 255), 2)\n",
    "                    except : \n",
    "                        continue\n",
    "\n",
    "    cv2.imshow('img', img)\n",
    "    if cv2.waitKey(1) == 27 :\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'red1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-50207d650f31>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m     \u001b[1;31m# 색상에 따른 마스크 생성\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m     \u001b[0mmask_red1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minRange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhsv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mred1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mred2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m     \u001b[0mmask_red2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minRange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhsv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mred3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mred4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'red1' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "# 영상 경로 설정\n",
    "video_path= './video1.mp4'\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "# 영상 이름\n",
    "video_file = video_path.split('/')[-1]\n",
    "video_name = video_file.split('.')[0]\n",
    "\n",
    "while True :\n",
    "    # 영상 읽기\n",
    "    ret, img = cap.read()\n",
    "    \n",
    "    # 마지막 프레임 확인\n",
    "    if ret is None:\n",
    "        break\n",
    "        \n",
    "    img = cv2.resize(img, (img.shape[1]//2, img.shape[0]//2))\n",
    "    blur = cv2.GaussianBlur( img, (3,3), 0 )    \n",
    "    hsv = cv2.cvtColor( blur, cv2.COLOR_BGR2HSV )\n",
    "    \n",
    "    # 색상에 따른 마스크 생성\n",
    "    mask_red1 = cv2.inRange(hsv, red1, red2)\n",
    "    mask_red2 = cv2.inRange(hsv, red3, red4)\n",
    "    \n",
    "    # 마스크 결합\n",
    "    mask_red = mask_red1 + mask_red2\n",
    "    \n",
    "    # 침식 (노이즈제거) -> 팽창(픽셀 살리기)\n",
    "    erosion_mask = cv2.erode(mask_red, kernel, iterations=1)\n",
    "    # cv2.imshow('erosion_mask', erosion_mask)\n",
    "    dilation_mask = cv2.dilate(erosion_mask, kernel2, iterations=1) \n",
    "    # cv2.imshow('dilation_mask', dilation_mask)\n",
    "    \n",
    "    contours, hierarchy = cv2.findContours(dilation_mask, cv2.RETR_CCOMP, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    mask_internal = np.zeros(dilation_mask.shape, dilation_mask.dtype)\n",
    "    for i in range(len(contours)) :\n",
    "        if hierarchy[0][i][3] != -1 :\n",
    "            cv2.drawContours(mask_internal, contours, i, 255, -1)\n",
    "            \n",
    "    numOfLabels, img_label, stats, centroids = cv2.connectedComponentsWithStats(mask_internal)\n",
    "    \n",
    "    for idx, centroid in enumerate(centroids) :\n",
    "        \n",
    "        if stats[idx][0] == 0 and stats[idx][1] == 0 :\n",
    "            continue\n",
    "        if np.any(np.isnan(centroid)) :\n",
    "            continue\n",
    "\n",
    "        x, y, w, h, area = stats[idx]\n",
    "        centerX, centerY = int(centroid[0]), int(centroid[1])\n",
    "\n",
    "        if area > 120 and abs(w-h) < 5 :\n",
    "            # cv2.rectangle(img, (x-10, y-10), (x+w+10, y+h+10), (0, 0, 255), 2)\n",
    "            # cv2.circle(img, ( centerX, centerY ), 2, (0, 255, 0), 2)\n",
    "            # print(x, y, w, h, area)\n",
    "\n",
    "#             detected_img = img[y-10 : y+h+10,  x-10 : x+w+10]\n",
    "#             gray_detected_img = cv2.cvtColor(detected_img, cv2.COLOR_BGR2GRAY)\n",
    "#             circles = cv2.HoughCircles(gray_detected_img, cv2.HOUGH_GRADIENT, 1, 100, param1=200, param2=30, minRadius=0, maxRadius=0)\n",
    "#             if circles is not None :\n",
    "#                 circles = np.uint16(np.around(circles))\n",
    "\n",
    "#                 for i in circles[0, :] :\n",
    "#                     cv2.circle(img, ( centerX, centerY ), 2, (0, 255, 0), 2)\n",
    "#                     cv2.rectangle(img, (x-10, y-10), (x+w+10, y+h+10), (0, 0, 255), 2)\n",
    "                \n",
    "            try : \n",
    "                detected_img = img[y-10 : y+h+10,  x-10 : x+w+10]\n",
    "                gray_detected_img = cv2.cvtColor(detected_img, cv2.COLOR_BGR2GRAY)\n",
    "                circles = cv2.HoughCircles(gray_detected_img, cv2.HOUGH_GRADIENT, 1, 100, param1=100, param2=30)\n",
    "                if circles is not None :\n",
    "                    circles = np.uint16(np.around(circles))\n",
    "\n",
    "                    for i in circles[0, :] :\n",
    "                        cv2.circle(img, ( centerX, centerY ), 2, (0, 255, 0), 2)\n",
    "                        cv2.rectangle(img, (x-10, y-10), (x+w+10, y+h+10), (0, 0, 255), 2)\n",
    "            except : \n",
    "                continue\n",
    "\n",
    "    cv2.imshow('img', img)\n",
    "    cv2.imshow('mask_internal', mask_internal)\n",
    "\n",
    "    if cv2.waitKey(1) == 27 :\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
