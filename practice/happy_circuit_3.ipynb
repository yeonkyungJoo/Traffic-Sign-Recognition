{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 표지판 예측 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# 파일 열고 URL주소 뒤에 [ ?kernel_name=py374 ] <- 붙여서 실행\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import random\n",
    "import os\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "import time\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Activation, Dropout, Flatten, Dense, GlobalAveragePooling2D, Conv2D, Conv2DTranspose, LeakyReLU, UpSampling2D\n",
    "from keras import optimizers\n",
    "# \n",
    "from keras.layers.normalization import BatchNormalization as BN\n",
    "\n",
    "from keras.layers import Lambda, Reshape, Add, AveragePooling2D, MaxPooling2D, Concatenate, SeparableConv2D\n",
    "from keras.models import Model\n",
    "from keras.losses import mse, binary_crossentropy\n",
    "from keras.utils import plot_model\n",
    "from keras import backend as K\n",
    "\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "from keras.regularizers import l2\n",
    "\n",
    "from keras.preprocessing.image import array_to_img, img_to_array, load_img\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from PIL import Image, ImageDraw, ImageFilter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.9\n",
    "sess  = tf.Session(config=config) \n",
    "keras.backend.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터세트 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dir_url : ./data/train/\n",
      "[INFO] loading images...\n",
      "NO_U-turn\n",
      "NO_left\n",
      "NO_parking_stop\n",
      "50\n",
      "60\n",
      "NO_right\n",
      "30\n",
      "[INFO] End loading images...\n"
     ]
    }
   ],
   "source": [
    "dir_url = './data/train/'\n",
    "\n",
    "print( 'dir_url : {}'.format(dir_url) )\n",
    "files = os.listdir(dir_url)\n",
    "i = 1\n",
    "\n",
    "print(\"[INFO] loading images...\")\n",
    "LABELS = set( [\"30\",\"50\",\"60\",\"NO_U-turn\",\"NO_left\",\"NO_parking_stop\",\"NO_right\"] )\n",
    "data = []\n",
    "labels = []\n",
    "train_path = './data/train'\n",
    "\n",
    "for files_list in files : \n",
    "    print(files_list) # 30, 50, 60\n",
    "    file = os.listdir(dir_url+files_list)\n",
    "    for image in os.listdir(dir_url+files_list):\n",
    "        imagepath = train_path + '/' + files_list + '/' + image\n",
    "        \n",
    "        img = cv2.imread(imagepath)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        img = cv2.resize(img,(64,64) )\n",
    "        data.append(img)\n",
    "        \n",
    "        if files_list not in LABELS:\n",
    "            continue\n",
    "        labels.append(files_list)\n",
    "        \n",
    "\n",
    "# convert the data and labels to NumPy arrays\n",
    "print(\"[INFO] End loading images...\")\n",
    "data = np.array(data)\n",
    "labels = np.array(labels)\n",
    "\n",
    "data = data / 255.0 \n",
    "\n",
    "# perform one-hot encoding on the labels\n",
    "lb = LabelBinarizer()\n",
    "labels = lb.fit_transform(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3018, 64, 64, 3)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터 셋 크기 확인\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['30', '50', '60', 'NO_U-turn', 'NO_left', 'NO_parking_stop',\n",
       "       'NO_right'], dtype='<U15')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 레이블 확인\n",
    "lb.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 레이블 길이 확인\n",
    "len(lb.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3018, 7)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 분리 - train / test 용\n",
    "(trainX, testX, trainY, testY) = train_test_split(data, labels, test_size=0.25, stratify=labels, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 생성\n",
    "\n",
    "- 컨볼루션 레이어 : 입력 이미지 크기 64 x 64, 입력 이미지 채널 3개, 필터 크기 3 x 3, 필터 수 32개, 활성화 함수 ‘relu’\n",
    "- 맥스풀링 레이어 : 풀 크기 2 x 2\n",
    "- 드롭 레이어\n",
    "- 컨볼루션 레이어 : 필터 크기 3 x 3, 필터 수 64개, 활성화 함수 ‘relu’\n",
    "- 맥스풀링 레이어 : 풀 크기 2 x 2\n",
    "- 드롭 레이어\n",
    "- 플래튼 레이어\n",
    "- 덴스 레이어 : 출력 뉴런 수 128개, 활성화 함수 ‘relu’\n",
    "- 드롭 레이어\n",
    "- 덴스 레이어 : 출력 뉴런 수 3개, 활성화 함수 ‘softmax’"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/team2/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/team2/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/team2/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/team2/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/team2/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/team2/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add( Conv2D( 32, kernel_size=(3,3), activation='relu', input_shape=(64,64,3) ) )\n",
    "model.add( MaxPooling2D( pool_size=(2,2) ) )\n",
    "model.add( Dropout(0.25) )\n",
    "\n",
    "model.add( Conv2D( 64, kernel_size=(3,3), activation='relu') )\n",
    "model.add( MaxPooling2D( pool_size=(2,2) ) )\n",
    "model.add( Dropout(0.25) )\n",
    "\n",
    "model.add( Flatten() )\n",
    "\n",
    "model.add( Dense(128, activation='relu') )\n",
    "model.add( Dropout(0.25) )\n",
    "\n",
    "model.add( Dense( len(lb.classes_), activation='softmax' ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 62, 62, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 31, 31, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 31, 31, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 29, 29, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 12544)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               1605760   \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 7)                 903       \n",
      "=================================================================\n",
      "Total params: 1,626,055\n",
      "Trainable params: 1,626,055\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 모델 구성 확인\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 모델 컴파일\n",
    "- [손실함수] \n",
    "- categorical_crossentropy 를 사용\n",
    "\n",
    "- [최적화 함수]\n",
    "- 1. 아담 \n",
    "    -> opt = Adam(lr=1e-3, decay=1e-3 / 50)\n",
    "- 2. SGD \n",
    "    -> opt = SGD(lr=1e-4, momentum=0.9, decay=1e-4 / args[\"epochs\"])\n",
    "- 3. rmsprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] compiling model...\n",
      "WARNING:tensorflow:From /home/team2/anaconda3/lib/python3.7/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/team2/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3295: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"[INFO] compiling model...\")\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer='rmsprop', metrics=['accuracy'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/team2/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Train on 1810 samples, validate on 453 samples\n",
      "Epoch 1/50\n",
      "1810/1810 [==============================] - 2s 1ms/step - loss: 1.7609 - acc: 0.4541 - val_loss: 1.2223 - val_acc: 0.5166\n",
      "Epoch 2/50\n",
      "1810/1810 [==============================] - 0s 220us/step - loss: 1.1993 - acc: 0.5425 - val_loss: 1.3325 - val_acc: 0.5585\n",
      "Epoch 3/50\n",
      "1810/1810 [==============================] - 0s 235us/step - loss: 0.9934 - acc: 0.6094 - val_loss: 0.9491 - val_acc: 0.5695\n",
      "Epoch 4/50\n",
      "1810/1810 [==============================] - 0s 252us/step - loss: 0.8254 - acc: 0.6552 - val_loss: 1.0257 - val_acc: 0.5872\n",
      "Epoch 5/50\n",
      "1810/1810 [==============================] - 0s 254us/step - loss: 0.7434 - acc: 0.7039 - val_loss: 0.9210 - val_acc: 0.6578\n",
      "Epoch 6/50\n",
      "1810/1810 [==============================] - 0s 261us/step - loss: 0.6346 - acc: 0.7481 - val_loss: 0.5873 - val_acc: 0.7792\n",
      "Epoch 7/50\n",
      "1810/1810 [==============================] - 0s 228us/step - loss: 0.5166 - acc: 0.8033 - val_loss: 0.5480 - val_acc: 0.7837\n",
      "Epoch 8/50\n",
      "1810/1810 [==============================] - 0s 247us/step - loss: 0.4707 - acc: 0.8260 - val_loss: 0.4279 - val_acc: 0.8543\n",
      "Epoch 9/50\n",
      "1810/1810 [==============================] - 0s 255us/step - loss: 0.3990 - acc: 0.8409 - val_loss: 0.6836 - val_acc: 0.6998\n",
      "Epoch 10/50\n",
      "1810/1810 [==============================] - 0s 240us/step - loss: 0.3840 - acc: 0.8630 - val_loss: 0.3774 - val_acc: 0.8433\n",
      "Epoch 11/50\n",
      "1810/1810 [==============================] - 0s 253us/step - loss: 0.2705 - acc: 0.9077 - val_loss: 0.2664 - val_acc: 0.9095\n",
      "Epoch 12/50\n",
      "1810/1810 [==============================] - 0s 236us/step - loss: 0.2691 - acc: 0.9000 - val_loss: 0.2554 - val_acc: 0.9007\n",
      "Epoch 13/50\n",
      "1810/1810 [==============================] - 0s 238us/step - loss: 0.2267 - acc: 0.9182 - val_loss: 0.4969 - val_acc: 0.8300\n",
      "Epoch 14/50\n",
      "1810/1810 [==============================] - 0s 241us/step - loss: 0.2362 - acc: 0.9105 - val_loss: 0.3100 - val_acc: 0.8653\n",
      "Epoch 15/50\n",
      "1810/1810 [==============================] - 0s 228us/step - loss: 0.1765 - acc: 0.9409 - val_loss: 0.3980 - val_acc: 0.8808\n",
      "Epoch 16/50\n",
      "1810/1810 [==============================] - 0s 239us/step - loss: 0.1498 - acc: 0.9525 - val_loss: 0.2469 - val_acc: 0.9051\n",
      "Epoch 17/50\n",
      "1810/1810 [==============================] - 1s 282us/step - loss: 0.1772 - acc: 0.9376 - val_loss: 0.2072 - val_acc: 0.9205\n",
      "Epoch 18/50\n",
      "1810/1810 [==============================] - 0s 253us/step - loss: 0.1212 - acc: 0.9575 - val_loss: 0.2154 - val_acc: 0.9117\n",
      "Epoch 19/50\n",
      "1810/1810 [==============================] - 1s 279us/step - loss: 0.1097 - acc: 0.9613 - val_loss: 0.1968 - val_acc: 0.9360\n",
      "Epoch 20/50\n",
      "1810/1810 [==============================] - 0s 276us/step - loss: 0.1148 - acc: 0.9646 - val_loss: 0.2871 - val_acc: 0.9029\n",
      "Epoch 21/50\n",
      "1810/1810 [==============================] - 0s 263us/step - loss: 0.0902 - acc: 0.9707 - val_loss: 0.2079 - val_acc: 0.9404\n",
      "Epoch 22/50\n",
      "1810/1810 [==============================] - 0s 234us/step - loss: 0.0850 - acc: 0.9729 - val_loss: 0.1795 - val_acc: 0.9426\n",
      "Epoch 23/50\n",
      "1810/1810 [==============================] - 0s 234us/step - loss: 0.0699 - acc: 0.9757 - val_loss: 0.2638 - val_acc: 0.9117\n",
      "Epoch 24/50\n",
      "1810/1810 [==============================] - 0s 249us/step - loss: 0.1043 - acc: 0.9674 - val_loss: 0.1580 - val_acc: 0.9514\n",
      "Epoch 25/50\n",
      "1810/1810 [==============================] - 0s 236us/step - loss: 0.0563 - acc: 0.9851 - val_loss: 0.2338 - val_acc: 0.9095\n",
      "Epoch 26/50\n",
      "1810/1810 [==============================] - 0s 254us/step - loss: 0.1276 - acc: 0.9564 - val_loss: 0.1845 - val_acc: 0.9426\n",
      "Epoch 27/50\n",
      "1810/1810 [==============================] - 0s 232us/step - loss: 0.0534 - acc: 0.9829 - val_loss: 0.1805 - val_acc: 0.9448\n",
      "Epoch 28/50\n",
      "1810/1810 [==============================] - 0s 231us/step - loss: 0.0750 - acc: 0.9707 - val_loss: 0.1609 - val_acc: 0.9581\n",
      "Epoch 29/50\n",
      "1810/1810 [==============================] - 0s 231us/step - loss: 0.0500 - acc: 0.9856 - val_loss: 0.1879 - val_acc: 0.9316\n",
      "Epoch 30/50\n",
      "1810/1810 [==============================] - 0s 234us/step - loss: 0.0397 - acc: 0.9884 - val_loss: 0.1610 - val_acc: 0.9625\n",
      "Epoch 31/50\n",
      "1810/1810 [==============================] - 0s 252us/step - loss: 0.0680 - acc: 0.9762 - val_loss: 0.1559 - val_acc: 0.9448\n",
      "Epoch 32/50\n",
      "1810/1810 [==============================] - 0s 265us/step - loss: 0.0559 - acc: 0.9796 - val_loss: 0.2772 - val_acc: 0.9007\n",
      "Epoch 33/50\n",
      "1810/1810 [==============================] - 0s 237us/step - loss: 0.0361 - acc: 0.9895 - val_loss: 0.1592 - val_acc: 0.9536\n",
      "Epoch 34/50\n",
      "1810/1810 [==============================] - 0s 229us/step - loss: 0.0284 - acc: 0.9912 - val_loss: 0.1995 - val_acc: 0.9426\n",
      "Epoch 35/50\n",
      "1810/1810 [==============================] - 0s 246us/step - loss: 0.0450 - acc: 0.9851 - val_loss: 0.1661 - val_acc: 0.9558\n",
      "Epoch 36/50\n",
      "1810/1810 [==============================] - 0s 251us/step - loss: 0.0270 - acc: 0.9906 - val_loss: 0.1520 - val_acc: 0.9492\n",
      "Epoch 37/50\n",
      "1810/1810 [==============================] - 0s 244us/step - loss: 0.0328 - acc: 0.9895 - val_loss: 0.2847 - val_acc: 0.9294\n",
      "Epoch 38/50\n",
      "1810/1810 [==============================] - 0s 246us/step - loss: 0.0464 - acc: 0.9834 - val_loss: 0.1495 - val_acc: 0.9536\n",
      "Epoch 39/50\n",
      "1810/1810 [==============================] - 0s 248us/step - loss: 0.0202 - acc: 0.9945 - val_loss: 0.1786 - val_acc: 0.9316\n",
      "Epoch 40/50\n",
      "1810/1810 [==============================] - 0s 251us/step - loss: 0.0351 - acc: 0.9901 - val_loss: 0.2059 - val_acc: 0.9360\n",
      "Epoch 41/50\n",
      "1810/1810 [==============================] - 0s 247us/step - loss: 0.0234 - acc: 0.9934 - val_loss: 0.1738 - val_acc: 0.9404\n",
      "Epoch 42/50\n",
      "1810/1810 [==============================] - 0s 245us/step - loss: 0.0241 - acc: 0.9928 - val_loss: 0.1550 - val_acc: 0.9514\n",
      "Epoch 43/50\n",
      "1810/1810 [==============================] - 0s 244us/step - loss: 0.0271 - acc: 0.9895 - val_loss: 0.1535 - val_acc: 0.9536\n",
      "Epoch 44/50\n",
      "1810/1810 [==============================] - 0s 244us/step - loss: 0.0162 - acc: 0.9961 - val_loss: 0.1527 - val_acc: 0.9669\n",
      "Epoch 45/50\n",
      "1810/1810 [==============================] - 0s 248us/step - loss: 0.0155 - acc: 0.9956 - val_loss: 0.1661 - val_acc: 0.9536\n",
      "Epoch 46/50\n",
      "1810/1810 [==============================] - 0s 241us/step - loss: 0.0126 - acc: 0.9950 - val_loss: 0.1687 - val_acc: 0.9514\n",
      "Epoch 47/50\n",
      "1810/1810 [==============================] - 0s 238us/step - loss: 0.0323 - acc: 0.9878 - val_loss: 0.1853 - val_acc: 0.9536\n",
      "Epoch 48/50\n",
      "1810/1810 [==============================] - 0s 247us/step - loss: 0.0192 - acc: 0.9950 - val_loss: 0.2000 - val_acc: 0.9647\n",
      "Epoch 49/50\n",
      "1810/1810 [==============================] - 0s 252us/step - loss: 0.0297 - acc: 0.9901 - val_loss: 0.1775 - val_acc: 0.9382\n",
      "Epoch 50/50\n",
      "1810/1810 [==============================] - 0s 238us/step - loss: 0.0221 - acc: 0.9912 - val_loss: 0.1469 - val_acc: 0.9669\n",
      "elapsed_time:24.516554355621338[sec]\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "# GPU 로 돌리기 (with 포함시킬것)\n",
    "with tf.device('/device:GPU:0'):\n",
    "    model.fit( trainX, trainY, batch_size=128, epochs= 50 , validation_split= 0.2 )\n",
    "    \n",
    "elapsed_time = time.time() - start\n",
    "print (\"elapsed_time:{}\".format(elapsed_time) + \"[sec]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] evaluating network...\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "             30       0.98      0.95      0.97       183\n",
      "             50       0.97      0.98      0.97       381\n",
      "             60       0.97      0.97      0.97       120\n",
      "      NO_U-turn       0.95      0.95      0.95        21\n",
      "        NO_left       0.97      0.97      0.97        30\n",
      "NO_parking_stop       1.00      1.00      1.00        15\n",
      "       NO_right       1.00      1.00      1.00         5\n",
      "\n",
      "       accuracy                           0.97       755\n",
      "      macro avg       0.98      0.97      0.98       755\n",
      "   weighted avg       0.97      0.97      0.97       755\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 모델 예측\n",
    "print(\"[INFO] evaluating network...\")\n",
    "predictions = model.predict(testX, batch_size=32)\n",
    "print(classification_report(testY.argmax(axis=1),\n",
    "                            predictions.argmax(axis=1), target_names=lb.classes_) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#모델을 JSON 파일 형식으로 만들어 저장하기\n",
    "model_json = model.to_json()\n",
    "with open(\"./model/model.json\", \"w\") as json_file : \n",
    "    json_file.write(model_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 가중치(weights) 저장\n",
    "model.save_weights('./model/model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 학습된 모델을 사용하여 ROI영역 레이블 예측 및 그리기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary packages\n",
    "from keras.models import load_model\n",
    "from collections import deque\n",
    "import numpy as np\n",
    "import argparse\n",
    "import pickle\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 독일 이미지로 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 1.]\n",
      "label text: NO_right\n"
     ]
    }
   ],
   "source": [
    "# 7가지 이미지 데이터 예측\n",
    "test_path_30 = './test_image/30_black.jpg'                             # 성공\n",
    "test_path_50 = './test_image/50_29.jpg'                                # 성공\n",
    "test_path_60 = './test_image/60_211.jpg'                              # 성공\n",
    "test_path_return = './test_image/test_no_return2.png'            # 성공\n",
    "test_path_no_left = './test_image/test_no_left.png'                # 성공\n",
    "test_path_no_right= './test_image/test_no_right.png'             # 실패 -> 배경이 검은색이라 예측실패인 걸로 예측됨\n",
    "test_path_no_right2= './test_image/test_no_parking.jpg'        # 성공\n",
    "test_path_no_parking = './test_image/test_no_parking.jpeg'   # 성공\n",
    "\n",
    "# 예측 테스트\n",
    "frame = cv2.imread(test_path_no_right2)\n",
    "frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "frame = cv2.resize(frame, (64, 64)).astype(\"float32\")\n",
    "\n",
    "# 예측\n",
    "preds = model.predict(np.expand_dims(frame, axis=0))[0]\n",
    "print(preds)\n",
    "\n",
    "# 레이블 표시\n",
    "label = lb.classes_[np.argmax(preds)]\n",
    "text = \"label text: {}\".format(label)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label : [0. 1. 0. 0. 0. 0. 0.]\n",
      "predict: 50\n"
     ]
    }
   ],
   "source": [
    "## ---------------------------------------------------------------------------------연경아 부탁해---------------------------------------------------------------------------------- ##\n",
    "# 전처리 과정을 거친 우리 데이터로 예측 테스트\n",
    "img = cv2.imread('./test_image/sample3_515.jpg')\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "blur = cv2.GaussianBlur(gray, (3, 3), 0)\n",
    "circles = cv2.HoughCircles(blur, cv2.HOUGH_GRADIENT, 1.5, 30, None, 570)\n",
    "\n",
    "#print(circles) # (x, y, 반지름)\n",
    "if circles is not None :\n",
    "    circles = np.uint16(np.around(circles))\n",
    "    for i in circles[0, :] :\n",
    "        x = i[0]\n",
    "        y = i[1]\n",
    "        r = i[2]\n",
    "        #print(x, y, r)\n",
    "        #print((x-r, y-r), (x+r, y+r))\n",
    "        cv2.circle(img, (i[0], i[1]), i[2], (0, 255, 0), 2)\n",
    "        cv2.circle(img, (i[0], i[1]), 2, (0, 0, 255), 5)\n",
    "        cv2.rectangle(img, (x-r, y-r), (x+r, y+r), (255, 0, 0), 1)\n",
    "      #x,y 원의 중심 좌표 / r : 반지름  \n",
    "frame = img[y-r:y+r, x-r:x+r]\n",
    "## -------------------------------------------------------------------------------------화이팅-------------------------------------------------------------------------------------------- ##\n",
    "\n",
    "\n",
    "frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "frame = cv2.resize(frame, (64, 64)).astype(\"float32\")\n",
    "\n",
    "# 예측 후 , roi 영역 표시\n",
    "preds = model.predict(np.expand_dims(frame, axis=0))[0]\n",
    "print('label : {}'.format(preds))\n",
    "\n",
    "#  레이블 확인\n",
    "label = lb.classes_[np.argmax(preds)]\n",
    "text = \"predict: {}\".format(label)\n",
    "print(text)\n",
    "cv2.putText(img, text, (x-50, y-50), cv2.FONT_HERSHEY_SIMPLEX, 1.25, (0, 255, 0), 5)\n",
    "\n",
    "# 이미지 확인\n",
    "cv2.imshow('final', img)\n",
    "\n",
    "# 종료 : 키보드 클릭\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 영상파일 예측 텍스트 첨부"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary packages\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from keras.models import load_model\n",
    "import numpy as np\n",
    "import pickle\n",
    "import cv2\n",
    "#저장된 JSON 파일로 부터 모델 로드하기\n",
    "from keras.models import model_from_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_file = open(\"./model/model.json\", \"r\")\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk\n"
     ]
    }
   ],
   "source": [
    "#로드한 모델에 Weight 로드하기\n",
    "loaded_model.load_weights(\"./model/model.h5\")\n",
    "print(\"Loaded model from disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#모델 컴파일 후 Evaluation\n",
    "loaded_model.compile(loss=\"categorical_crossentropy\", optimizer=\"rmsprop\", metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imutils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 영상 파일 경로\n",
    "video_path = './video/video1.mp4'\n",
    "cap = cv2.VideoCapture(video_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  비디오 writer와 프레임 크기 초기화\n",
    "writer = None\n",
    "(W, H) = (None,None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10161 total frames in video\n"
     ]
    }
   ],
   "source": [
    "# 전체 비디오 처리에 걸리는 시간을 추정하기 위해 비디오파일의 총 프레임 수를 결정\n",
    "try : \n",
    "    prop = cv2.cv.CV_CAP_PROP_FRAME_COUNT if imutils.is_cv2() \\\n",
    "            else cv2.CAP_PROP_FRAME_COUNT\n",
    "    total = int( cap.get(prop) )\n",
    "    print(\"{} total frames in video\".format(total) )\n",
    "except :\n",
    "    print(\"could not determine # of frames in video\")\n",
    "    print(\"no approx. completion time can be provided\")\n",
    "    total = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "video1.mp4\n",
      "video1\n"
     ]
    }
   ],
   "source": [
    "video_file = video_path.split('/')[-1]\n",
    "video_name = video_file.split('.')[0]\n",
    "print(video_file)\n",
    "print(video_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "988.0 426.0\n",
      "993.0 427.0\n",
      "993.0 423.0\n",
      "1340.0 556.5\n",
      "993.0 427.0\n",
      "1341.0 556.5\n",
      "1341.5 556.0\n",
      "1345.5 557.0\n",
      "1348.0 556.0\n",
      "1348.0 556.0\n",
      "1351.0 557.0\n",
      "1352.5 553.0\n",
      "1355.0 557.0\n",
      "1355.0 561.0\n",
      "1355.0 551.0\n",
      "1362.0 557.0\n",
      "can`t open video\n"
     ]
    }
   ],
   "source": [
    "# 영상 파일 경로\n",
    "video_path = './video/video1.mp4'\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "while True :\n",
    "    ret, img = cap.read()                            # ret : 프레임 존재 유무/ img : 프레임 읽기( cap.read() )\n",
    "\n",
    "    if not ret :                                           # 비디오의 마지막 프레임 확인  \n",
    "        print('can`t open video')\n",
    "        break\n",
    "\n",
    "    if W is None or H is None:                    # 프레임의 크기가 잡히지 않는 경우 프레임 크기를 잡는다.\n",
    "        (H, W) = img.shape[:2]\n",
    "\n",
    "    img2 = img.copy()\n",
    "## ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- ## \n",
    "\n",
    "    # HSV 영상으로 변환\n",
    "    hsv = cv2.cvtColor(img2, cv2.COLOR_BGR2HSV)\n",
    "    img2 = cv2.bilateralFilter(img, 9, 105, 105)\n",
    "    r, g, b = cv2.split(img2)\n",
    "    equalize1= cv2.equalizeHist(r)\n",
    "    equalize2= cv2.equalizeHist(g)\n",
    "    equalize3= cv2.equalizeHist(b)\n",
    "    equalize = cv2.merge((equalize1, equalize2, equalize3))\n",
    "    img2 = equalize\n",
    "\n",
    "    # 색상별 영역 지정\n",
    "    red1 = np.array([0, 50, 50])\n",
    "    red2 = np.array([15, 255, 255])\n",
    "    red3 = np.array([165, 50, 50])\n",
    "    red4 = np.array([180, 255, 255])\n",
    "\n",
    "    # 색상에 따른 마스크 생성\n",
    "    mask_red1 = cv2.inRange(hsv, red1, red2)\n",
    "    mask_red2 = cv2.inRange(hsv, red3, red4)\n",
    "    mask_red = mask_red1 + mask_red2\n",
    "\n",
    "    numOfLabels, img_label, stats, centroids = cv2.connectedComponentsWithStats(mask_red2)\n",
    "\n",
    "\n",
    "    for idx, centroid in enumerate(centroids) :\n",
    "        if stats[idx][0] == 0 and stats[idx][1] == 0 :\n",
    "            continue\n",
    "\n",
    "        if np.any(np.isnan(centroid)) :\n",
    "            continue\n",
    "\n",
    "        x, y, W, H, area = stats[idx]                                       # x,y -> 좌표 / W,H -> 너비 , 높이\n",
    "        centerX, centerY = int(centroid[0]), int(centroid[1])\n",
    "        #cv2.circle(img, (centerX, centerY), i[2], (0, 255, 0), 2)\n",
    "        #cv2.circle(img, (centerX, centerY), 2, (0, 0, 255), 5)\n",
    "        \n",
    "        gray_img = cv2.cvtColor(img2, cv2.COLOR_BGR2GRAY)\n",
    "        if area > 50 and abs( W - H ) < 5 : \n",
    "            gray_detected_img   = gray_img[ y : y + H , x : x + W ]\n",
    "            # gray_detected_img  = cv2.cvtColor(detected_img, cv2.COLOR_BGR2GRAY)\n",
    "            #gray_detected_img  = cv2.resize( gray_detected_img, (gray_detected_img.shape[1]*5, gray_detected_img.shape[0]*5) )\n",
    "            circles                    = cv2.HoughCircles(gray_img[ y : y + H , x : x + W ],            # 입력 영샹 , 1채널 배열\n",
    "                                                                      cv2.HOUGH_GRADIENT,      # 검출 방식 선택\n",
    "                                                                      1,                                      # 입력영상과 경사 누적의 해상도 반비례율, 1: 입력과 동일, 값이 커질수록 부정확\n",
    "                                                                      100,                                  # 원들 중심간의 최소 거리, 0 : 에러 (동심원 검출 불가)\n",
    "                                                                      param1=50,                       # 캐니 엣지에 전달할 스레시 홀드 최대 값\n",
    "                                                                      param2=30,                       # \n",
    "                                                                      minRadius=10,                   # 최소 반지름의 크기\n",
    "                                                                      maxRadius=0 )                   # 최대 반지름의 크기 \n",
    "\n",
    "            if circles is not None :\n",
    "                circles = np.uint16( np.around(circles) )\n",
    "\n",
    "                for i in circles[0, : ] :\n",
    "                    # 표지판 이미지 추출\n",
    "                    frame = img[ y - 4 : y + H + 4 , x - 4 : x + W + 4 ]\n",
    "                    \n",
    "                    try : \n",
    "                        # bgr -> rgb 로 배열순서 변경\n",
    "                        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "                        # 리사이즈 : 64 * 64\n",
    "                        frame = cv2.resize(frame, (64, 64) )\n",
    "                        # 예측\n",
    "                        preds = model.predict(np.expand_dims(frame, axis=0))[0]\n",
    "\n",
    "                        #  레이블 확인\n",
    "                        label = lb.classes_[np.argmax(preds)]\n",
    "                        text = \"{}\".format(label)\n",
    "\n",
    "                        cv2.putText( img, text, ( x , y + 100 ), cv2.FONT_HERSHEY_SIMPLEX, 1.0, ( 0, 255, 0 ), 5)\n",
    "                        cv2.rectangle(img, (x - 4, y - 4), (x + W + 4, y + H + 4), ( 255, 0, 0 ), 1)\n",
    "                        # print(i)\n",
    "                        # print(x,y)\n",
    "                        a = (x+x+W)/2\n",
    "                        b =  (y+y+H)/2\n",
    "                        print(a,b)\n",
    "                        #cv2.circle(img, (,), i[2], (0, 255, 0), 2)\n",
    "                        #cv2.circle(img, (i[0], i[1]), 2, (0, 0, 255), 5) # 이미지 / 중심좌표 / 반지름 / 색 / 두께\n",
    "                    except :\n",
    "                        continue\n",
    "## ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- ##           \n",
    "    cv2.imshow('video_file', img)        # 화면에 표시\n",
    "\n",
    "    if cv2.waitKey(1) == 27 :\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "keras-gpu",
   "language": "python",
   "name": "py374"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
