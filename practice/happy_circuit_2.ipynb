{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 표지판 예측 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파일 열고 URL주소 뒤에 [ ?kernel_name=py374 ] <- 붙여서 실행\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import random\n",
    "import os\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "import time\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Activation, Dropout, Flatten, Dense, GlobalAveragePooling2D, Conv2D, Conv2DTranspose, LeakyReLU, UpSampling2D\n",
    "from keras import optimizers\n",
    "# \n",
    "from keras.layers.normalization import BatchNormalization as BN\n",
    "\n",
    "from keras.layers import Lambda, Reshape, Add, AveragePooling2D, MaxPooling2D, Concatenate, SeparableConv2D\n",
    "from keras.models import Model\n",
    "from keras.losses import mse, binary_crossentropy\n",
    "from keras.utils import plot_model\n",
    "from keras import backend as K\n",
    "\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "from keras.regularizers import l2\n",
    "\n",
    "from keras.preprocessing.image import array_to_img, img_to_array, load_img\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from PIL import Image, ImageDraw, ImageFilter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.9\n",
    "sess  = tf.Session(config=config) \n",
    "keras.backend.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터세트 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dir_url : ./data/train/\n",
      "[INFO] loading images...\n",
      "NO_U-turn\n",
      "NO_left\n",
      "NO_parking_stop\n",
      "50\n",
      "60\n",
      "NO_right\n",
      "30\n",
      "[INFO] End loading images...\n"
     ]
    }
   ],
   "source": [
    "dir_url = './data/train/'\n",
    "\n",
    "print( 'dir_url : {}'.format(dir_url) )\n",
    "files = os.listdir(dir_url)\n",
    "i = 1\n",
    "\n",
    "print(\"[INFO] loading images...\")\n",
    "LABELS = set( [\"30\",\"50\",\"60\",\"NO_U-turn\",\"NO_left\",\"NO_parking_stop\",\"NO_right\"] )\n",
    "data = []\n",
    "labels = []\n",
    "train_path = './data/train'\n",
    "\n",
    "for files_list in files : \n",
    "    print(files_list) # 30, 50, 60\n",
    "    file = os.listdir(dir_url+files_list)\n",
    "    for image in os.listdir(dir_url+files_list):\n",
    "        imagepath = train_path + '/' + files_list + '/' + image\n",
    "        \n",
    "        img = cv2.imread(imagepath)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        img = cv2.resize(img,(64,64) )\n",
    "        data.append(img)\n",
    "        \n",
    "        if files_list not in LABELS:\n",
    "            continue\n",
    "        labels.append(files_list)\n",
    "        \n",
    "\n",
    "# convert the data and labels to NumPy arrays\n",
    "print(\"[INFO] End loading images...\")\n",
    "data = np.array(data)\n",
    "labels = np.array(labels)\n",
    "\n",
    "data = data / 255.0 \n",
    "\n",
    "# perform one-hot encoding on the labels\n",
    "lb = LabelBinarizer()\n",
    "labels = lb.fit_transform(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3018, 64, 64, 3)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터 셋 크기 확인\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['30', '50', '60', 'NO_U-turn', 'NO_left', 'NO_parking_stop',\n",
       "       'NO_right'], dtype='<U15')"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 레이블 확인\n",
    "lb.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 레이블 길이 확인\n",
    "len(lb.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3018, 7)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 분리 - train / test 용\n",
    "(trainX, testX, trainY, testY) = train_test_split(data, labels, test_size=0.25, stratify=labels, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 생성\n",
    "\n",
    "- 컨볼루션 레이어 : 입력 이미지 크기 64 x 64, 입력 이미지 채널 3개, 필터 크기 3 x 3, 필터 수 32개, 활성화 함수 ‘relu’\n",
    "- 맥스풀링 레이어 : 풀 크기 2 x 2\n",
    "- 드롭 레이어\n",
    "- 컨볼루션 레이어 : 필터 크기 3 x 3, 필터 수 64개, 활성화 함수 ‘relu’\n",
    "- 맥스풀링 레이어 : 풀 크기 2 x 2\n",
    "- 드롭 레이어\n",
    "- 플래튼 레이어\n",
    "- 덴스 레이어 : 출력 뉴런 수 128개, 활성화 함수 ‘relu’\n",
    "- 드롭 레이어\n",
    "- 덴스 레이어 : 출력 뉴런 수 3개, 활성화 함수 ‘softmax’"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add( Conv2D( 32, kernel_size=(3,3), activation='relu', input_shape=(64,64,3) ) )\n",
    "model.add( MaxPooling2D( pool_size=(2,2) ) )\n",
    "model.add( Dropout(0.25) )\n",
    "\n",
    "model.add( Conv2D( 64, kernel_size=(3,3), activation='relu') )\n",
    "model.add( MaxPooling2D( pool_size=(2,2) ) )\n",
    "model.add( Dropout(0.25) )\n",
    "\n",
    "model.add( Flatten() )\n",
    "\n",
    "model.add( Dense(128, activation='relu') )\n",
    "model.add( Dropout(0.25) )\n",
    "\n",
    "model.add( Dense( len(lb.classes_), activation='softmax' ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_5 (Conv2D)            (None, 62, 62, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 31, 31, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 31, 31, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 29, 29, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 12544)             0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 128)               1605760   \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 7)                 903       \n",
      "=================================================================\n",
      "Total params: 1,626,055\n",
      "Trainable params: 1,626,055\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 모델 구성 확인\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 모델 컴파일\n",
    "- [손실함수] \n",
    "- categorical_crossentropy 를 사용\n",
    "\n",
    "- [최적화 함수]\n",
    "- 1. 아담 \n",
    "    -> opt = Adam(lr=1e-3, decay=1e-3 / 50)\n",
    "- 2. SGD \n",
    "    -> opt = SGD(lr=1e-4, momentum=0.9, decay=1e-4 / args[\"epochs\"])\n",
    "- 3. rmsprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] compiling model...\n"
     ]
    }
   ],
   "source": [
    "print(\"[INFO] compiling model...\")\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer='rmsprop', metrics=['accuracy'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1810 samples, validate on 453 samples\n",
      "Epoch 1/50\n",
      "1810/1810 [==============================] - 1s 428us/step - loss: 1.9242 - acc: 0.3945 - val_loss: 1.2912 - val_acc: 0.5121\n",
      "Epoch 2/50\n",
      "1810/1810 [==============================] - 0s 230us/step - loss: 1.3023 - acc: 0.4994 - val_loss: 1.6340 - val_acc: 0.5342\n",
      "Epoch 3/50\n",
      "1810/1810 [==============================] - 0s 275us/step - loss: 1.1735 - acc: 0.5271 - val_loss: 1.1063 - val_acc: 0.6358\n",
      "Epoch 4/50\n",
      "1810/1810 [==============================] - 0s 255us/step - loss: 0.9808 - acc: 0.6227 - val_loss: 1.0951 - val_acc: 0.6313\n",
      "Epoch 5/50\n",
      "1810/1810 [==============================] - 0s 265us/step - loss: 0.8649 - acc: 0.6481 - val_loss: 0.7549 - val_acc: 0.6887\n",
      "Epoch 6/50\n",
      "1810/1810 [==============================] - 0s 242us/step - loss: 0.7426 - acc: 0.7044 - val_loss: 0.7783 - val_acc: 0.7373\n",
      "Epoch 7/50\n",
      "1810/1810 [==============================] - 0s 246us/step - loss: 0.6353 - acc: 0.7613 - val_loss: 0.8116 - val_acc: 0.6137\n",
      "Epoch 8/50\n",
      "1810/1810 [==============================] - 0s 255us/step - loss: 0.5531 - acc: 0.7928 - val_loss: 0.6006 - val_acc: 0.7770\n",
      "Epoch 9/50\n",
      "1810/1810 [==============================] - 1s 293us/step - loss: 0.5034 - acc: 0.8160 - val_loss: 0.4608 - val_acc: 0.8035\n",
      "Epoch 10/50\n",
      "1810/1810 [==============================] - 0s 274us/step - loss: 0.4346 - acc: 0.8282 - val_loss: 0.4953 - val_acc: 0.8035\n",
      "Epoch 11/50\n",
      "1810/1810 [==============================] - 0s 271us/step - loss: 0.3731 - acc: 0.8575 - val_loss: 0.3804 - val_acc: 0.8521\n",
      "Epoch 12/50\n",
      "1810/1810 [==============================] - 1s 279us/step - loss: 0.3412 - acc: 0.8724 - val_loss: 0.3315 - val_acc: 0.8742\n",
      "Epoch 13/50\n",
      "1810/1810 [==============================] - 0s 264us/step - loss: 0.3042 - acc: 0.8928 - val_loss: 0.3315 - val_acc: 0.8609\n",
      "Epoch 14/50\n",
      "1810/1810 [==============================] - 0s 239us/step - loss: 0.2820 - acc: 0.9000 - val_loss: 0.3032 - val_acc: 0.8786\n",
      "Epoch 15/50\n",
      "1810/1810 [==============================] - 0s 249us/step - loss: 0.2331 - acc: 0.9149 - val_loss: 0.3790 - val_acc: 0.8675\n",
      "Epoch 16/50\n",
      "1810/1810 [==============================] - 0s 258us/step - loss: 0.1871 - acc: 0.9331 - val_loss: 0.2658 - val_acc: 0.9161\n",
      "Epoch 17/50\n",
      "1810/1810 [==============================] - 0s 257us/step - loss: 0.1964 - acc: 0.9298 - val_loss: 0.2769 - val_acc: 0.8985\n",
      "Epoch 18/50\n",
      "1810/1810 [==============================] - 0s 248us/step - loss: 0.1622 - acc: 0.9475 - val_loss: 0.3412 - val_acc: 0.8521\n",
      "Epoch 19/50\n",
      "1810/1810 [==============================] - 0s 251us/step - loss: 0.2062 - acc: 0.9276 - val_loss: 0.2244 - val_acc: 0.9161\n",
      "Epoch 20/50\n",
      "1810/1810 [==============================] - 0s 261us/step - loss: 0.1362 - acc: 0.9558 - val_loss: 0.3188 - val_acc: 0.8631\n",
      "Epoch 21/50\n",
      "1810/1810 [==============================] - 0s 244us/step - loss: 0.1194 - acc: 0.9575 - val_loss: 0.1853 - val_acc: 0.9492\n",
      "Epoch 22/50\n",
      "1810/1810 [==============================] - 0s 240us/step - loss: 0.1276 - acc: 0.9580 - val_loss: 0.2371 - val_acc: 0.9161\n",
      "Epoch 23/50\n",
      "1810/1810 [==============================] - 0s 257us/step - loss: 0.1179 - acc: 0.9635 - val_loss: 0.2091 - val_acc: 0.9382\n",
      "Epoch 24/50\n",
      "1810/1810 [==============================] - 0s 227us/step - loss: 0.0971 - acc: 0.9674 - val_loss: 0.1721 - val_acc: 0.9603\n",
      "Epoch 25/50\n",
      "1810/1810 [==============================] - 0s 241us/step - loss: 0.0806 - acc: 0.9757 - val_loss: 0.1818 - val_acc: 0.9360\n",
      "Epoch 26/50\n",
      "1810/1810 [==============================] - 0s 242us/step - loss: 0.0844 - acc: 0.9746 - val_loss: 0.2381 - val_acc: 0.9139\n",
      "Epoch 27/50\n",
      "1810/1810 [==============================] - 0s 245us/step - loss: 0.0791 - acc: 0.9729 - val_loss: 0.2271 - val_acc: 0.9492\n",
      "Epoch 28/50\n",
      "1810/1810 [==============================] - 0s 266us/step - loss: 0.1063 - acc: 0.9635 - val_loss: 0.2354 - val_acc: 0.9007\n",
      "Epoch 29/50\n",
      "1810/1810 [==============================] - 0s 244us/step - loss: 0.0528 - acc: 0.9840 - val_loss: 0.1630 - val_acc: 0.9514\n",
      "Epoch 30/50\n",
      "1810/1810 [==============================] - 0s 235us/step - loss: 0.0641 - acc: 0.9762 - val_loss: 0.1852 - val_acc: 0.9448\n",
      "Epoch 31/50\n",
      "1810/1810 [==============================] - 0s 247us/step - loss: 0.0753 - acc: 0.9779 - val_loss: 0.1831 - val_acc: 0.9514\n",
      "Epoch 32/50\n",
      "1810/1810 [==============================] - 0s 233us/step - loss: 0.0668 - acc: 0.9785 - val_loss: 0.1704 - val_acc: 0.9492\n",
      "Epoch 33/50\n",
      "1810/1810 [==============================] - 0s 237us/step - loss: 0.0394 - acc: 0.9901 - val_loss: 0.1879 - val_acc: 0.9470\n",
      "Epoch 34/50\n",
      "1810/1810 [==============================] - 0s 221us/step - loss: 0.0621 - acc: 0.9801 - val_loss: 0.1454 - val_acc: 0.9514\n",
      "Epoch 35/50\n",
      "1810/1810 [==============================] - 0s 255us/step - loss: 0.0433 - acc: 0.9840 - val_loss: 0.2008 - val_acc: 0.9492\n",
      "Epoch 36/50\n",
      "1810/1810 [==============================] - 0s 245us/step - loss: 0.0402 - acc: 0.9878 - val_loss: 0.1605 - val_acc: 0.9603\n",
      "Epoch 37/50\n",
      "1810/1810 [==============================] - 1s 284us/step - loss: 0.0418 - acc: 0.9884 - val_loss: 0.1830 - val_acc: 0.9492\n",
      "Epoch 38/50\n",
      "1810/1810 [==============================] - 0s 257us/step - loss: 0.0498 - acc: 0.9823 - val_loss: 0.2057 - val_acc: 0.9227\n",
      "Epoch 39/50\n",
      "1810/1810 [==============================] - 0s 261us/step - loss: 0.0310 - acc: 0.9901 - val_loss: 0.1899 - val_acc: 0.9581\n",
      "Epoch 40/50\n",
      "1810/1810 [==============================] - 0s 255us/step - loss: 0.0307 - acc: 0.9917 - val_loss: 0.1729 - val_acc: 0.9558\n",
      "Epoch 41/50\n",
      "1810/1810 [==============================] - 0s 269us/step - loss: 0.0387 - acc: 0.9878 - val_loss: 0.2007 - val_acc: 0.9514\n",
      "Epoch 42/50\n",
      "1810/1810 [==============================] - 0s 234us/step - loss: 0.0217 - acc: 0.9928 - val_loss: 0.2163 - val_acc: 0.9404\n",
      "Epoch 43/50\n",
      "1810/1810 [==============================] - 0s 241us/step - loss: 0.0347 - acc: 0.9890 - val_loss: 0.1485 - val_acc: 0.9558\n",
      "Epoch 44/50\n",
      "1810/1810 [==============================] - 0s 265us/step - loss: 0.0184 - acc: 0.9950 - val_loss: 0.1558 - val_acc: 0.9558\n",
      "Epoch 45/50\n",
      "1810/1810 [==============================] - 0s 237us/step - loss: 0.0395 - acc: 0.9878 - val_loss: 0.1669 - val_acc: 0.9536\n",
      "Epoch 46/50\n",
      "1810/1810 [==============================] - 0s 254us/step - loss: 0.0204 - acc: 0.9945 - val_loss: 0.1823 - val_acc: 0.9514\n",
      "Epoch 47/50\n",
      "1810/1810 [==============================] - 0s 263us/step - loss: 0.0270 - acc: 0.9928 - val_loss: 0.2217 - val_acc: 0.9470\n",
      "Epoch 48/50\n",
      "1810/1810 [==============================] - 0s 265us/step - loss: 0.0201 - acc: 0.9917 - val_loss: 0.2142 - val_acc: 0.9647\n",
      "Epoch 49/50\n",
      "1810/1810 [==============================] - 0s 255us/step - loss: 0.0362 - acc: 0.9884 - val_loss: 0.1730 - val_acc: 0.9514\n",
      "Epoch 50/50\n",
      "1810/1810 [==============================] - 0s 258us/step - loss: 0.0138 - acc: 0.9961 - val_loss: 0.2124 - val_acc: 0.9514\n",
      "elapsed_time:23.478972911834717[sec]\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "# GPU 로 돌리기 (with 포함시킬것)\n",
    "with tf.device('/device:GPU:0'):\n",
    "    model.fit( trainX, trainY, batch_size=128, epochs= 50 , validation_split= 0.2 )\n",
    "    \n",
    "elapsed_time = time.time() - start\n",
    "print (\"elapsed_time:{}\".format(elapsed_time) + \"[sec]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] evaluating network...\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "             30       0.99      0.92      0.95       183\n",
      "             50       0.95      0.99      0.97       381\n",
      "             60       0.97      0.96      0.97       120\n",
      "      NO_U-turn       1.00      0.95      0.98        21\n",
      "        NO_left       1.00      1.00      1.00        30\n",
      "NO_parking_stop       1.00      0.93      0.97        15\n",
      "       NO_right       1.00      1.00      1.00         5\n",
      "\n",
      "       accuracy                           0.97       755\n",
      "      macro avg       0.99      0.96      0.98       755\n",
      "   weighted avg       0.97      0.97      0.97       755\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 모델 예측\n",
    "print(\"[INFO] evaluating network...\")\n",
    "predictions = model.predict(testX, batch_size=32)\n",
    "print(classification_report(testY.argmax(axis=1),\n",
    "                            predictions.argmax(axis=1), target_names=lb.classes_) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "#모델을 JSON 파일 형식으로 만들어 저장하기\n",
    "model_json = model.to_json()\n",
    "with open(\"./model/model.json\", \"w\") as json_file : \n",
    "    json_file.write(model_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 가중치(weights) 저장\n",
    "model.save_weights('./model/model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 학습된 모델을 사용하여 ROI영역 레이블 예측 및 그리기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary packages\n",
    "from keras.models import load_model\n",
    "from collections import deque\n",
    "import numpy as np\n",
    "import argparse\n",
    "import pickle\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 독일 이미지로 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 1.]\n",
      "label text: NO_right\n"
     ]
    }
   ],
   "source": [
    "# 7가지 이미지 데이터 예측\n",
    "test_path_30 = './test_image/30_black.jpg'                             # 성공\n",
    "test_path_50 = './test_image/50_29.jpg'                                # 성공\n",
    "test_path_60 = './test_image/60_211.jpg'                              # 성공\n",
    "test_path_return = './test_image/test_no_return2.png'            # 성공\n",
    "test_path_no_left = './test_image/test_no_left.png'                # 성공\n",
    "test_path_no_right= './test_image/test_no_right.png'             # 실패 -> 배경이 검은색이라 예측실패인 걸로 예측됨\n",
    "test_path_no_right2= './test_image/test_no_parking.jpg'        # 성공\n",
    "test_path_no_parking = './test_image/test_no_parking.jpeg'   # 성공\n",
    "\n",
    "# 예측 테스트\n",
    "frame = cv2.imread(test_path_no_right2)\n",
    "frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "frame = cv2.resize(frame, (64, 64)).astype(\"float32\")\n",
    "\n",
    "# 예측\n",
    "preds = model.predict(np.expand_dims(frame, axis=0))[0]\n",
    "print(preds)\n",
    "\n",
    "# 레이블 표시\n",
    "label = lb.classes_[np.argmax(preds)]\n",
    "text = \"label text: {}\".format(label)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label : [0. 1. 0. 0. 0. 0. 0.]\n",
      "predict: 50\n"
     ]
    }
   ],
   "source": [
    "## ---------------------------------------------------------------------------------연경아 부탁해---------------------------------------------------------------------------------- ##\n",
    "# 전처리 과정을 거친 우리 데이터로 예측 테스트\n",
    "img = cv2.imread('./test_image/sample3_515.jpg')\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "blur = cv2.GaussianBlur(gray, (3, 3), 0)\n",
    "circles = cv2.HoughCircles(blur, cv2.HOUGH_GRADIENT, 1.5, 30, None, 570)\n",
    "\n",
    "#print(circles) # (x, y, 반지름)\n",
    "if circles is not None :\n",
    "    circles = np.uint16(np.around(circles))\n",
    "    for i in circles[0, :] :\n",
    "        x = i[0]\n",
    "        y = i[1]\n",
    "        r = i[2]\n",
    "        #print(x, y, r)\n",
    "        #print((x-r, y-r), (x+r, y+r))\n",
    "        cv2.circle(img, (i[0], i[1]), i[2], (0, 255, 0), 2)\n",
    "        cv2.circle(img, (i[0], i[1]), 2, (0, 0, 255), 5)\n",
    "        cv2.rectangle(img, (x-r, y-r), (x+r, y+r), (255, 0, 0), 1)\n",
    "      #x,y 원의 중심 좌표 / r : 반지름  \n",
    "frame = img[y-r:y+r, x-r:x+r]\n",
    "## -------------------------------------------------------------------------------------화이팅-------------------------------------------------------------------------------------------- ##\n",
    "\n",
    "\n",
    "frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "frame = cv2.resize(frame, (64, 64)).astype(\"float32\")\n",
    "\n",
    "# 예측 후 , roi 영역 표시\n",
    "preds = model.predict(np.expand_dims(frame, axis=0))[0]\n",
    "print('label : {}'.format(preds))\n",
    "\n",
    "#  레이블 확인\n",
    "label = lb.classes_[np.argmax(preds)]\n",
    "text = \"predict: {}\".format(label)\n",
    "print(text)\n",
    "cv2.putText(img, text, (x-50, y-50), cv2.FONT_HERSHEY_SIMPLEX, 1.25, (0, 255, 0), 5)\n",
    "\n",
    "# 이미지 확인\n",
    "cv2.imshow('final', img)\n",
    "\n",
    "# 종료 : 키보드 클릭\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 영상파일 예측 텍스트 첨부"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary packages\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from keras.models import load_model\n",
    "import numpy as np\n",
    "import pickle\n",
    "import cv2\n",
    "#저장된 JSON 파일로 부터 모델 로드하기\n",
    "from keras.models import model_from_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_file = open(\"./model/model.json\", \"r\")\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk\n"
     ]
    }
   ],
   "source": [
    "#로드한 모델에 Weight 로드하기\n",
    "loaded_model.load_weights(\"./model/model.h5\")\n",
    "print(\"Loaded model from disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#모델 컴파일 후 Evaluation\n",
    "loaded_model.compile(loss=\"categorical_crossentropy\", optimizer=\"rmsprop\", metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imutils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 영상 파일 경로\n",
    "video_path = './video/video1.mp4'\n",
    "cap = cv2.VideoCapture(video_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  비디오 writer와 프레임 크기 초기화\n",
    "writer = None\n",
    "(W, H) = (None,None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10161 total frames in video\n"
     ]
    }
   ],
   "source": [
    "# 전체 비디오 처리에 걸리는 시간을 추정하기 위해 비디오파일의 총 프레임 수를 결정\n",
    "try : \n",
    "    prop = cv2.cv.CV_CAP_PROP_FRAME_COUNT if imutils.is_cv2() \\\n",
    "            else cv2.CAP_PROP_FRAME_COUNT\n",
    "    total = int( cap.get(prop) )\n",
    "    print(\"{} total frames in video\".format(total) )\n",
    "except :\n",
    "    print(\"could not determine # of frames in video\")\n",
    "    print(\"no approx. completion time can be provided\")\n",
    "    total = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "video1.mp4\n",
      "video1\n"
     ]
    }
   ],
   "source": [
    "video_file = video_path.split('/')[-1]\n",
    "video_name = video_file.split('.')[0]\n",
    "print(video_file)\n",
    "print(video_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if cap.isOpened() :\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    delay = int(1000/fps)\n",
    "    print(fps)    # 30.0028139633606\n",
    "    print(delay) # 33\n",
    "\n",
    "## ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- ## \n",
    "    while True :\n",
    "        ret, img = cap.read()                      # 다음 프레임 읽기\n",
    "        \n",
    "        if ret :                                           # 프레임 읽기 정상 \n",
    "## ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- ## \n",
    "            img2 = img.copy()\n",
    "            (H, W) = img.shape[:2]\n",
    "           \n",
    "            # HSV 영상으로 변환\n",
    "            hsv = cv2.cvtColor(img2, cv2.COLOR_BGR2HSV)\n",
    "            img2 = cv2.bilateralFilter(img, 9, 105, 105)\n",
    "            r, g, b = cv2.split(img2)\n",
    "            equalize1= cv2.equalizeHist(r)\n",
    "            equalize2= cv2.equalizeHist(g)\n",
    "            equalize3= cv2.equalizeHist(b)\n",
    "            equalize = cv2.merge((equalize1, equalize2, equalize3))\n",
    "            img2 = equalize\n",
    "\n",
    "            # 색상별 영역 지정\n",
    "            red1 = np.array([0, 50, 50])\n",
    "            red2 = np.array([15, 255, 255])\n",
    "            red3 = np.array([165, 50, 50])\n",
    "            red4 = np.array([180, 255, 255])\n",
    "\n",
    "            # 색상에 따른 마스크 생성\n",
    "            mask_red1 = cv2.inRange(hsv, red1, red2)\n",
    "            mask_red2 = cv2.inRange(hsv, red3, red4)\n",
    "            mask_red = mask_red1 + mask_red2\n",
    "\n",
    "            numOfLabels, img_label, stats, centroids = cv2.connectedComponentsWithStats(mask_red2)\n",
    "            \n",
    "            \n",
    "            for idx, centroid in enumerate(centroids) :\n",
    "                if stats[idx][0] == 0 and stats[idx][1] == 0 :\n",
    "                    continue\n",
    "\n",
    "                if np.any(np.isnan(centroid)) :\n",
    "                    continue\n",
    "\n",
    "                x, y, W, H, area = stats[idx]                                       # x,y -> 좌표 / W,H -> 너비 , 높이\n",
    "                centerX, centerY = int(centroid[0]), int(centroid[1])\n",
    "\n",
    "                if area > 50 and abs( W - H ) < 5 : \n",
    "                    # 원 검출\n",
    "                    detected_img          = img2[ y : y + H , x : x + W ]\n",
    "                    gray_detected_img  = cv2.cvtColor(detected_img, cv2.COLOR_BGR2GRAY)\n",
    "                    gray_detected_img  = cv2.resize(gray_detected_img, (gray_detected_img.shape[1]*5, gray_detected_img.shape[0]*5))\n",
    "                    circles                    = cv2.HoughCircles(gray_detected_img,\n",
    "                                                                              cv2.HOUGH_GRADIENT,\n",
    "                                                                              1, 100, param1=50, param2=30, minRadius=10, maxRadius=0)\n",
    "                    \n",
    "                    if circles is not None :\n",
    "                        circles = np.uint16( np.around(circles) )\n",
    "                        \n",
    "                        for i in circles[0, : ] :\n",
    "                            # 표지판 이미지 추출\n",
    "                            frame = img[ y - 3 : y + H + 3 , x - 3 : x + W + 3 ]\n",
    "                            try : \n",
    "                                # bgr -> rgb 로 배열순서 변경\n",
    "                                frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "                                # 리사이즈 : 64 * 64\n",
    "                                frame = cv2.resize(frame, (64, 64) )\n",
    "                                # 예측\n",
    "                                preds = model.predict(np.expand_dims(frame, axis=0))[0]\n",
    "\n",
    "                                #  레이블 확인\n",
    "                                label = lb.classes_[np.argmax(preds)]\n",
    "                                text = \"predict: {}\".format(label)\n",
    "                                \n",
    "                                cv2.putText( img, text, ( x + 50, y + 50 ), cv2.FONT_HERSHEY_SIMPLEX, 1.0, ( 0, 255, 0 ), 5)\n",
    "                                cv2.rectangle(img, (x - 3, y - 3), (x + W + 3, y + H + 3), ( 255, 0, 0 ), 1)\n",
    "                            except :\n",
    "                                continue\n",
    "## ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- ##           \n",
    "            cv2.imshow('video_file', img)        # 화면에 표시\n",
    "            #cv2.waitKey(10)                     # fps에 맞게 시간 지연\n",
    "            if cv2.waitKey(1) == 27 :\n",
    "                cap.release()\n",
    "                cv2.destroyAllWindows()\n",
    "        else :\n",
    "            break\n",
    "else : # 영상 경로 확인\n",
    "    print(\"can't open video.\")\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 영상 파일 경로\n",
    "video_path = './video/video1.mp4'\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "if cap.isOpened() :\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    delay = int(1000/fps)\n",
    "    #print(fps)    # 30.0028139633606\n",
    "    #print(delay) # 33\n",
    "\n",
    "## ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- ## \n",
    "    while True :\n",
    "        ret, img = cap.read()                            # ret : 프레임 존재 유무/ img : 프레임 읽기( cap.read() )\n",
    "        \n",
    "        if not ret :                                           # 비디오의 마지막 프레임 확인  \n",
    "            break\n",
    "        \n",
    "        if W is None or H is None:                    # 프레임의 크기가 잡히지 않는 경우 프레임 크기를 잡는다.\n",
    "            (H, W) = img.shape[:2]\n",
    "\n",
    "        img2 = img.copy()\n",
    "## ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- ## \n",
    "            \n",
    "\n",
    "        # HSV 영상으로 변환\n",
    "        hsv = cv2.cvtColor(img2, cv2.COLOR_BGR2HSV)\n",
    "        img2 = cv2.bilateralFilter(img, 9, 105, 105)\n",
    "        r, g, b = cv2.split(img2)\n",
    "        equalize1= cv2.equalizeHist(r)\n",
    "        equalize2= cv2.equalizeHist(g)\n",
    "        equalize3= cv2.equalizeHist(b)\n",
    "        equalize = cv2.merge((equalize1, equalize2, equalize3))\n",
    "        img2 = equalize\n",
    "\n",
    "        # 색상별 영역 지정\n",
    "        red1 = np.array([0, 50, 50])\n",
    "        red2 = np.array([15, 255, 255])\n",
    "        red3 = np.array([165, 50, 50])\n",
    "        red4 = np.array([180, 255, 255])\n",
    "\n",
    "        # 색상에 따른 마스크 생성\n",
    "        mask_red1 = cv2.inRange(hsv, red1, red2)\n",
    "        mask_red2 = cv2.inRange(hsv, red3, red4)\n",
    "        mask_red = mask_red1 + mask_red2\n",
    "\n",
    "        numOfLabels, img_label, stats, centroids = cv2.connectedComponentsWithStats(mask_red2)\n",
    "\n",
    "\n",
    "        for idx, centroid in enumerate(centroids) :\n",
    "            if stats[idx][0] == 0 and stats[idx][1] == 0 :\n",
    "                continue\n",
    "\n",
    "            if np.any(np.isnan(centroid)) :\n",
    "                continue\n",
    "\n",
    "            x, y, W, H, area = stats[idx]                                       # x,y -> 좌표 / W,H -> 너비 , 높이\n",
    "            centerX, centerY = int(centroid[0]), int(centroid[1])\n",
    "\n",
    "            if area > 50 and abs( W - H ) < 5 : \n",
    "                # 원 검출\n",
    "                detected_img          = img2[ y : y + H , x : x + W ]\n",
    "                gray_detected_img  = cv2.cvtColor(detected_img, cv2.COLOR_BGR2GRAY)\n",
    "                gray_detected_img  = cv2.resize(gray_detected_img, (gray_detected_img.shape[1]*5, gray_detected_img.shape[0]*5))\n",
    "                circles                    = cv2.HoughCircles(gray_detected_img,\n",
    "                                                                          cv2.HOUGH_GRADIENT,\n",
    "                                                                          1, 100, param1=50, param2=30, minRadius=10, maxRadius=0)\n",
    "\n",
    "                if circles is not None :\n",
    "                    circles = np.uint16( np.around(circles) )\n",
    "\n",
    "                    for i in circles[0, : ] :\n",
    "                        # 표지판 이미지 추출\n",
    "                        frame = img[ y - 4 : y + H + 4 , x - 4 : x + W + 4 ]\n",
    "                        #frame = img[ y  : y + H  , x  : x + W ]\n",
    "                        try : \n",
    "                            # bgr -> rgb 로 배열순서 변경\n",
    "                            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "                            # 리사이즈 : 64 * 64\n",
    "                            frame = cv2.resize(frame, (64, 64) )\n",
    "                            # 예측\n",
    "                            preds = model.predict(np.expand_dims(frame, axis=0))[0]\n",
    "\n",
    "                            #  레이블 확인\n",
    "                            label = lb.classes_[np.argmax(preds)]\n",
    "                            text = \"predict: {}\".format(label)\n",
    "\n",
    "                            cv2.putText( img, text, ( x + 50, y + 50 ), cv2.FONT_HERSHEY_SIMPLEX, 1.0, ( 0, 255, 0 ), 5)\n",
    "                            cv2.rectangle(img, (x - 4, y - 4), (x + W + 4, y + H + 4), ( 255, 0, 0 ), 1)\n",
    "                        except :\n",
    "                            continue\n",
    "## ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- ##           \n",
    "        cv2.imshow('video_file', img)        # 화면에 표시\n",
    "\n",
    "        if cv2.waitKey(1) == 27 :\n",
    "            cap.release()\n",
    "            cv2.destroyAllWindows()\n",
    "                \n",
    "                \n",
    "else : # 영상 경로 확인\n",
    "    print(\"can't open video.\")\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(3.4.7) /io/opencv/modules/highgui/src/window.cpp:358: error: (-215:Assertion failed) size.width>0 && size.height>0 in function 'imshow'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-118-cc868e075ffe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     85\u001b[0m                         \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;31m## ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- ##\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m     \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'video_file'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m        \u001b[0;31m# 화면에 표시\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwaitKey\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m27\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31merror\u001b[0m: OpenCV(3.4.7) /io/opencv/modules/highgui/src/window.cpp:358: error: (-215:Assertion failed) size.width>0 && size.height>0 in function 'imshow'\n"
     ]
    }
   ],
   "source": [
    "# 영상 파일 경로\n",
    "video_path = './video/video1.mp4'\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "while True :\n",
    "    ret, img = cap.read()                            # ret : 프레임 존재 유무/ img : 프레임 읽기( cap.read() )\n",
    "\n",
    "    if not ret :                                           # 비디오의 마지막 프레임 확인  \n",
    "        print('can`t open video')\n",
    "        break\n",
    "\n",
    "    if W is None or H is None:                    # 프레임의 크기가 잡히지 않는 경우 프레임 크기를 잡는다.\n",
    "        (H, W) = img.shape[:2]\n",
    "\n",
    "    img2 = img.copy()\n",
    "## ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- ## \n",
    "\n",
    "    # HSV 영상으로 변환\n",
    "    hsv = cv2.cvtColor(img2, cv2.COLOR_BGR2HSV)\n",
    "    img2 = cv2.bilateralFilter(img, 9, 105, 105)\n",
    "    r, g, b = cv2.split(img2)\n",
    "    equalize1= cv2.equalizeHist(r)\n",
    "    equalize2= cv2.equalizeHist(g)\n",
    "    equalize3= cv2.equalizeHist(b)\n",
    "    equalize = cv2.merge((equalize1, equalize2, equalize3))\n",
    "    img2 = equalize\n",
    "\n",
    "    # 색상별 영역 지정\n",
    "    red1 = np.array([0, 50, 50])\n",
    "    red2 = np.array([15, 255, 255])\n",
    "    red3 = np.array([165, 50, 50])\n",
    "    red4 = np.array([180, 255, 255])\n",
    "\n",
    "    # 색상에 따른 마스크 생성\n",
    "    mask_red1 = cv2.inRange(hsv, red1, red2)\n",
    "    mask_red2 = cv2.inRange(hsv, red3, red4)\n",
    "    mask_red = mask_red1 + mask_red2\n",
    "\n",
    "    numOfLabels, img_label, stats, centroids = cv2.connectedComponentsWithStats(mask_red2)\n",
    "\n",
    "\n",
    "    for idx, centroid in enumerate(centroids) :\n",
    "        if stats[idx][0] == 0 and stats[idx][1] == 0 :\n",
    "            continue\n",
    "\n",
    "        if np.any(np.isnan(centroid)) :\n",
    "            continue\n",
    "\n",
    "        x, y, W, H, area = stats[idx]                                       # x,y -> 좌표 / W,H -> 너비 , 높이\n",
    "        centerX, centerY = int(centroid[0]), int(centroid[1])\n",
    "\n",
    "        if area > 50 and abs( W - H ) < 5 : \n",
    "            # 원 검출\n",
    "            detected_img          = img2[ y : y + H , x : x + W ]\n",
    "            gray_detected_img  = cv2.cvtColor(detected_img, cv2.COLOR_BGR2GRAY)\n",
    "            gray_detected_img  = cv2.resize(gray_detected_img, (gray_detected_img.shape[1]*5, gray_detected_img.shape[0]*5))\n",
    "            circles                    = cv2.HoughCircles(gray_detected_img,\n",
    "                                                                      cv2.HOUGH_GRADIENT,\n",
    "                                                                      1, 100, param1=50, param2=30, minRadius=10, maxRadius=0)\n",
    "\n",
    "            if circles is not None :\n",
    "                circles = np.uint16( np.around(circles) )\n",
    "\n",
    "                for i in circles[0, : ] :\n",
    "                    # 표지판 이미지 추출\n",
    "                    frame = img[ y - 4 : y + H + 4 , x - 4 : x + W + 4 ]\n",
    "                    #frame = img[ y  : y + H  , x  : x + W ]\n",
    "                    try : \n",
    "                        # bgr -> rgb 로 배열순서 변경\n",
    "                        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "                        # 리사이즈 : 64 * 64\n",
    "                        frame = cv2.resize(frame, (64, 64) )\n",
    "                        # 예측\n",
    "                        preds = model.predict(np.expand_dims(frame, axis=0))[0]\n",
    "\n",
    "                        #  레이블 확인\n",
    "                        label = lb.classes_[np.argmax(preds)]\n",
    "                        text = \"predict: {}\".format(label)\n",
    "\n",
    "                        cv2.putText( img, text, ( x + 80, y + 80 ), cv2.FONT_HERSHEY_SIMPLEX, 1.0, ( 0, 255, 0 ), 5)\n",
    "                        cv2.rectangle(img, (x - 4, y - 4), (x + W + 4, y + H + 4), ( 255, 0, 0 ), 1)\n",
    "                        #cv2.circle(frame, (i[0], i[1]), i[2], (0, 255, 0), 2)\n",
    "                        #cv2.circle(frame, (i[0], i[1]), 2, (0, 0, 255), 5)\n",
    "                    except :\n",
    "                        continue\n",
    "## ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- ##           \n",
    "    cv2.imshow('video_file', img)        # 화면에 표시\n",
    "\n",
    "    if cv2.waitKey(1) == 27 :\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "keras-gpu",
   "language": "python",
   "name": "py374"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
